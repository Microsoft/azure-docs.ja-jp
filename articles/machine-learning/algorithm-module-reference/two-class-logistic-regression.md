---
title: '2 クラスのロジスティック回帰: モジュール リファレンス'
titleSuffix: Azure Machine Learning
description: Azure Machine Learning で 2 クラスのロジスティック回帰モジュールを使用し、2 つのみの結果を予測するのに使用できるロジスティック回帰モデルを作成する方法について説明します。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 10/22/2019
ms.openlocfilehash: 541d1001f8b5881f2773f795d7bd849704cbd796
ms.sourcegitcommit: 812bc3c318f513cefc5b767de8754a6da888befc
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 02/12/2020
ms.locfileid: "77153691"
---
# <a name="two-class-logistic-regression-module"></a>2 クラスのロジスティック回帰モジュール

この記事では Azure Machine Learning デザイナー (プレビュー) 内のモジュールについて説明します。

2 つのみの結果を予測するのに使用できるロジスティック回帰モデルを作成するには、このモジュールを使用します。 

ロジスティック回帰は、さまざまな種類の問題をモデル化するのに使用される有名な統計手法です。 このアルゴリズムは "*教師あり学習*" 手法であるため、モデルをトレーニングするための結果をあらかじめ含んだデータセットを用意する必要があります。  

### <a name="about-logistic-regression"></a>ロジスティック回帰について  

ロジスティック回帰は、統計学において、ある結果が起こる確率を予測する手段としてよく知られている手法で、特に分類タスクで広く使われています。 このアルゴリズムは、データをロジスティック関数にフィッティングすることで事象の発生確率を予測します。
  
このモジュールでは、分類アルゴリズムが二値変数またはバイナリ変数に最適化されています。 複数の結果を分類する必要がある場合は、[多クラスのロジスティック回帰](./multiclass-logistic-regression.md)モジュールを使用してください。

##  <a name="how-to-configure"></a>構成方法  

このモデルをトレーニングするには、ラベル列またはクラス列を含んだデータセットを用意する必要があります。 このモジュールは 2 クラスの問題を意図しているため、ラベル列またはクラス列には厳密に 2 つの値が格納されていることが必要です。 

たとえば、[Voted] というラベル列であれば、その値には "Yes" と "No" が考えられます。 または、[Credit Risk] であれば、"High" と "Low" という値が考えられるでしょう。 
  
1.  **2 クラスのロジスティック回帰**モジュールをパイプラインに追加します。  
  
2.  **[Create trainer mode]\(トレーナー モードの作成\)** オプションを設定して、モデルのトレーニング方法を指定します。  
  
    -   **Single Parameter (単一パラメーター)** : モデルの構成方法がわかっている場合、特定の値のセットを引数として渡すことができます。  
  
3.  **[Optimization tolerance]\(最適化の許容範囲\)** に、モデルを最適化する際に使用するしきい値を指定します。 指定したしきい値をイテレーション間の改善が下回った場合に、アルゴリズムは解に収束したと見なされ、トレーニングが終了します。  
  
4.  正則化パラメーター L1 と L2 に使用する値を **[L1 regularization weight]\(L1 正則化の重み\)** と **[L2 regularization weight]\(L2 正則化の重み\)** に入力します。 どちらも 0 以外の値にすることをおすすめします。  
     "*正則化*" とは、極端な係数の値を備えるモデルにペナルティーを与えることによってオーバーフィットを防止する手法です。 正則化は、仮説の誤りに対し、係数値に関連付けられているペナルティを加算することによって機能します。 これにより、極端な係数の値を持った正確なモデルにはより大きなペナルティが与えられる一方、相対的に値が控えめで正確でないモデルに与えられるペナルティは小さくなります。  
  
     L1 正則化と L2 正則化とでは、効果と用途が異なります。  
  
    -   L1 は、疎なモデルに適用でき、高次元のデータを扱う際に役立ちます。  
  
    -   これに対し、L2 正則化は、疎ではないデータに適しています。  
  
     このアルゴリズムは、L1 正則化と L2 正則化の値に対する線形の組み合わせをサポートします。つまり、<code>x = L1</code> かつ <code>y = L2</code> である場合、正則化項の線形包が <code>ax + by = c</code> で定義されます。  
  
    > [!NOTE]
    >  L1 正則化と L2 正則化について、さらに詳しく知りたい場合は、 次の記事を参照してください。L1 正則化と L2 正則化の違いや、モデルのフィッティングに及ぼす影響が、ロジスティック回帰モデルとニューラル ネットワーク モデルのコード サンプルを使って解説されています: 「[機械学習向けの L1および L2 正規化](https://msdn.microsoft.com/magazine/dn904675.aspx)」  
    >
    > ロジスティック回帰モデルには、L1 項と L2 項に対するさまざまな線形結合が考案されてきました ([エラスティック ネット型の正則化](https://wikipedia.org/wiki/Elastic_net_regularization)など)。 こうした結合を参照しながら、自分のモデルに合った効果的な線形結合を定義することをおすすめします。
      
5.  *L-BFGS* 最適化に使用するメモリ量を **[Memory size for L-BFGS]\(L-BFGS のメモリ サイズ\)** に指定します。  
  
     L-BFGS は "Limited memory Broyden-Fletcher-Goldfarb-Shanno" の略です。 パラメーター推定の最適化アルゴリズムとして広く使用されています。 このパラメーターは、次のステップの計算用に保存する過去の位置と傾きの数を指定します。  
  
     この最適化パラメーターによって、次のステップと方向の計算に使用されるメモリ量が制限されます。 指定するメモリ量を小さくすると、トレーニングにかかる時間は短縮されますが、正確さが低下します。  
  
6.  **[Random number seed]\(乱数シード\)** に整数値を入力します。 同じパイプラインを複数回にわたって実行したときの結果に再現性を確保したい場合は、シード値を定義することが大切です。  
  
  
8. タグ付けされたデータセットをパイプラインに追加し、いずれかの[トレーニング モジュール](module-reference.md)を接続します。  
  
    -   **[Create trainer mode]\(トレーナー モードの作成\)** を **[Single Parameter]\(単一パラメーター\)** に設定した場合は、[モデルのトレーニング](./train-model.md) モジュールを使用します。  
  
9. パイプラインを実行します。  
  
## <a name="results"></a>[結果]

トレーニングの完了後:
 
  
+ 新しいデータについての予測を行うために、トレーニング済みのモデルと新しいデータを[モデルのスコア付け](./score-model.md)モジュールの入力として使用します。 


## <a name="next-steps"></a>次のステップ

Azure Machine Learning で[使用できる一連のモジュール](module-reference.md)を参照してください。 