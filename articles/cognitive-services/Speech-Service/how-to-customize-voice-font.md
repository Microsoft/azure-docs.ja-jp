---
title: カスタム音声フォントを作成する方法
titlesuffix: Azure Cognitive Services
description: この記事では、Text to Speech での音声のカスタマイズの概要を説明します。この機能を使うと、認識可能な独自のブランド音声を作成できます。
services: cognitive-services
author: PanosPeriorellis
manager: cgronlun
ms.service: cognitive-services
ms.component: speech-service
ms.topic: conceptual
ms.date: 05/07/2018
ms.author: panosper
ms.openlocfilehash: e2c176e35cbc75747230e429d0ddae9d420db8b5
ms.sourcegitcommit: b0f39746412c93a48317f985a8365743e5fe1596
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 12/04/2018
ms.locfileid: "52867582"
---
# <a name="creating-custom-voice-fonts"></a>カスタム音声フォントの作成

Text to Speech (TTS) の音声カスタマイズ機能を使うと、"*音声フォント*" つまり認識可能な独自のブランドの音声を作成できます。 

音声フォントを作成するには、スタジオで録音し、関連するスクリプトをトレーニング データとしてアップロードします。 サービスは、録音に合わせて調整された一意の音声モデルを作成します。 この音声フォントを使用して、音声を合成できます。 

概念実証のために少量のデータで始めることができます。 ただし、データが多いほど、より自然で本格的な音声になります。

## <a name="prerequisites"></a>前提条件

Azure アカウントと音声サービスへのサブスクリプションが必要です。 まだない場合は、[作成](https://docs.microsoft.com/azure/cognitive-services/speech-service/get-started)してください。 次のように、サブスクリプションを Custom Voice ポータルに接続します。

1. アクセスの申請に使用したのと同じ Microsoft アカウントを使って、[Custom Voice ポータル](https://customvoice.ai)にサインインします。

2. 右上のアカウント名の下にある **[Subscriptions]\(サブスクリプション\)** に移動します。

    ![サブスクリプション](media/custom-voice/subscriptions.png)

3. [Subscriptions]\(サブスクリプション\) ページで **[Connect existing subscription]\(既存のサブスクリプションに接続する\)** を選択します。 Speech Services はさまざまなリージョンをサポートしていることに注意してください。 サブスクリプション キーが作成されたリージョンを調べて、キーを正しいサブポータルに接続していることを確認してください。  

4. 次の例に示すように、テーブルにサブスクリプション キーを貼り付けます。 各サブスクリプションには 2 つのキーがあり、それらのいずれかを使用できます。

     ![サブスクリプションを追加する](media/custom-voice/add-subscription.png)

準備ができました。

## <a name="prepare-recordings-and-transcripts"></a>録音とトランスクリプトを準備する

音声トレーニング データセットは、オーディオ ファイルのセットと、音声ファイルのトランスクリプトを含む 1 つのテキスト ファイルで構成されます。

これらのファイルは、2 つの方法で準備できます。 スクリプトを記述して音声タレントに読ませるか、一般に使用可能な音声を利用してテキストに書き起こします。 後者を行う場合は、"うーん" やその他のつなぎ語、口ごもり、不明瞭な単語、誤った発音などの流ちょうでない部分をオーディオ ファイルから削除します。

良質の音声フォントを作成するには、静かな部屋で高品質のマイクを使って録音します。 一定の音量、速さ、ピッチ、および表現方法で話すことが、優れたデジタル音声の作成には不可欠です。 

製品用の音声を作成するには、専門の録音スタジオと音声タレントを使うことをお勧めします。 詳細については、[カスタム音声用の音声サンプルを録音する方法](record-custom-voice-samples.md)に関するページを参照してください。

### <a name="audio-files"></a>オーディオ ファイル

各オーディオ ファイルには、1 つの発話が含まれる必要があります (1 つの文、対話システムの 1 つのターンなど)。 すべてのファイルは、同じ言語である必要があります。 (複数言語のカスタム音声はサポートされません。)また、オーディオ ファイルにはファイル名拡張子が `.wav` の一意の数値ファイル名が付いている必要があります。

オーディオ ファイルは次のように準備する必要があります。 他の形式はサポートされておらず、拒否されます。

| **プロパティ** | **値** |
| ------------ | --------- |
| ファイル形式  | RIFF (.wav)|
| サンプリング レート| 少なくとも 16,000 Hz |
| サンプル形式| PCM、16 ビット |
| ファイル名    | 数値、拡張子は `.wav` |
| アーカイブ形式| .zip      |
| 最大アーカイブ サイズ|200 MB|

> [!NOTE]
> サンプリング レートが 16,000 Hz より低い .wav ファイルは拒否されます。 .zip ファイルにサンプリング レートが異なる波が含まれている場合は、16,000 Hz 以上の波だけがインポートされます。
> 現在、ポータルには 200 MB までの .zip アーカイブがインポートされます。 ただし、複数のアーカイブをアップロードできます。 許可されるデータセットの最大数は、Free サブスクリプション ユーザーの場合は .zip ファイル 10 個、Standard サブスクリプション ユーザーの場合は 50 個です。

### <a name="transcripts"></a>トランスクリプト

文字起こしファイルはプレーンテキスト ファイル (ANSI、UTF-8、UTF-8-BOM、UTF-16-LE、UTF-16-BE) です。 文字起こしファイルの各行は、オーディオ ファイルの名前、タブ (コード ポイント 9) 文字、トランスクリプトという順序になっている必要があります。 空白行は許可されていません。

例: 

```
0000000001  This is the waistline, and it's falling.
0000000002  We have trouble scoring.
0000000003  It was Janet Maslin.
```

カスタム音声システムは、テキストを小文字に変換し、余分な区切り記号を削除することで、トランスクリプトを正規化します。 トランスクリプトが、対応するオーディオ録音の文字起こしに対して 100% 正確であることが重要です。

> [!TIP]
> 製品用のテキスト読み上げ音声を作成するときは、音声の範囲と効率性の両方を考慮に入れている発話 (または記述スクリプト) を選択します。 求めている結果がうまく得られない場合、 Microsoft へのご相談方法の詳細について、[Custom Voice チームにお問い合わせください](mailto:speechsupport@microsoft.com)。

## <a name="upload-your-datasets"></a>データセットをアップロードする

オーディオ ファイルのアーカイブとトランスクリプトを準備したら、[Custom Voice サービス ポータル](https://customvoice.ai)でそれらをアップロードします。

> [!NOTE]
> アップロードした後は、データセットを編集できません。 たとえば、一部のオーディオ ファイルのトランスクリプトを収め忘れた場合や、誤って間違った性別を選んだ場合などは、データセット全体をもう一度アップロードする必要があります。 アップロードを開始する前に、データセットと設定を綿密に確認してください。

1. ポータルにサインインします。

2. メイン ページの **[Custom Voice]** の下の **[Data]\(データ\)** を選択します。   

    **[My Voice]\(マイ音声)** テーブルが表示されます。 まだ音声データセットをアップロードしていない場合は空です。

3. **[Import data]\(データのインポート\)** を選択して、新規データセット アップロード用のページを開きます。 

    ![音声データをインポートする](media/custom-voice/import-voice-data.png)

4. 表示されたフィールドに名前と説明を入力します。 

5. 音声フォントのロケールを選択します。 ロケール情報が録音データおよびスクリプトの言語と一致することを確認します。 

6. 音声を使用している話者の性別を選択します。

7. アップロードするスクリプト ファイルとオーディオ ファイルを選択します。 

8. **[Import]\(インポート\)** を選択してデータをアップロードします。 大きいデータ セットでは、インポートに数分かかることがあります。

> [!NOTE]
> Free サブスクリプション ユーザーは、一度に 2 個のデータセットをアップロードできます。 Standard サブスクリプション ユーザーは、5 個のデータセットを同時にアップロードできます。 制限に達した場合は、少なくとも 1 つのデータセットのインポートが終わるまで待機します。 その後、やり直してください。

アップロードが完了すると、**[My Voice Data]\(マイ音声データ\)** テーブルがもう一度表示されます。 アップロードしたばかりのデータセットに対応するエントリが表示されます。 

アップロードの完了後に、データセットは自動的に検証されます。 データ検証には、ファイル形式、サイズ、サンプル速度を確認する、オーディオ ファイルの一連のチェックが含まれます。 文字起こしファイルのチェックでは、ファイル形式が確認され、いくつかのテキスト正規化が行われます。 音声認識を使用して、発話が文字起こしされます。 その後結果のテキストは、指定したトランスクリプトと比較されます。

![マイ音声データ](media/custom-voice/my-voice-data.png)

次の表に、インポートされたデータセットの処理状態を示します。 

| 状態 | 意味
| ----- | -------
| `NotStarted` | データセットは受信され、処理のためにキューに入れられています。
| `Running` | データセットは検証中です。
| `Succeeded` | データセットは検証が済み、音声フォントの作成に使用できるようになっています。

検証が完了すると、各データセットで一致した発話の合計数を **[Utterance]\(発話\)** 列で確認できます。

レポートをダウンロードして、各録音の発音スコアとノイズ レベルを確認できます。 発音スコアの範囲は 0 ～ 100 です。 スコアが 70 未満の場合は、通常、音声のエラーまたはスクリプトの不一致を示しています。 アクセントが強いと発音スコアが下がることがあり、生成されるデジタル音声に影響します。

高い信号雑音比 (SNR) は、オーディオのノイズが低いことを示します。 一般に、専門スタジオでの録音によって、SNR が 50 以上に達するようにできます。 SNR が 20 未満のオーディオでは、生成される音声に明らかなノイズが含まれる可能性があります。

発音スコアが低い場合や SNR が悪い場合は、発話を録音し直すことを検討してください。 再録音できない場合は、それらの発話をデータセットから除外してもかまいません。

## <a name="build-your-voice-font"></a>音声フォントを作成する

データセットの検証後、それを使用してカスタム音声フォントを作成できます。 

1.  **[Custom Voice]** ドロップダウン メニューの **[Models]\(モデル\)** を選択します。
 
    **[My Voice Fonts]\(マイ音声フォント\)** テーブルに、既に作成したカスタム音声フォントの一覧が表示されます。

1. テーブル タイトルの下にある **[Create voices]\(音声の作成\)** を選択します。 

    音声フォント作成ページが表示されます。 テーブルの 1 行目には、現在のロケールが表示されます。 別の言語で音声を作成するには、ロケールを変更します。 ロケールは、音声の作成に使用されるデータセットと同じである必要があります。

1. データセットをアップロードしたときと同様に、このモデルを識別するのに役立つ説明と名前を入力します。 

    名前は慎重に選択します。 ここで入力する名前が、SSML 入力の一部としての音声合成の要求時に、音声を指定するために使用する名前になります。 文字、数字、およびいくつかの区切り文字 ("-"、"_"、"("、")" など) だけを使用できます。

    **[Description]\(説明)** フィールドの一般的な用途は、モデルの作成に使用されたデータセットの名前を記録することです。

1. 音声フォントの性別を選択します。 データセットの性別と一致している必要があります。

1. 音声フォントのトレーニングに使用するデータセットを選択します。 使用するすべてのデータセットの話者は同じである必要があります。

1. **[Create]\(作成\)** をクリックして、音声フォントの作成を開始します。

    ![モデルの作成](media/custom-voice/create-model.png)

新しいモデルが **[My Voice Fonts]\(マイ音声フォント\)** テーブルに表示されます。 

![[My Voice Fonts]\(マイ音声フォント\)](media/custom-voice/my-voice-fonts.png)

表示される状態は、次に示すように、データセットから音声フォントへの変換プロセスを反映しています。

| 状態 | 意味
| ----- | -------
| `NotStarted` | 音声フォント作成要求は、処理のためにキューに置かれました。
| `Running` | 音声フォントを作成中です。
| `Succeeded` | 音声フォントは作成は済みで、展開可能です。

トレーニング時間は、処理されるオーディオ データの量によって異なります。 標準的な時間は、数百個の発話で約 30 分、20,000 個の発話で 40 時間です。

> [!NOTE]
> Free サブスクリプション ユーザーは、一度には 1 つの音声フォントをトレーニングできます。 Standard サブスクリプション ユーザーは、3 つの音声を同時にトレーニングできます。 制限に達した場合は、少なくとも 1 つの音声フォントのトレーニングが終わるまで待ってから、やり直します。

## <a name="test-your-voice-font"></a>音声フォントをテストする

音声フォントが正常に作成されたら、使用のために展開する前にテストすることができます。 **[Operations]\(操作\)** 列の **[Test]\(テスト\)** を選択します。 選択した音声フォントのテスト ページが表示されます。 その音声のテスト要求をまだ送信していない場合、テーブルは空です。

テキスト要求送信用のポップアップ メニューを表示するには、テーブル タイトルの下にある **[Test with text]\(テキストをテストする\)** ボタンを選択します。 プレーン テキストまたは SSML でテスト要求を送信できます。 最大入力サイズは、SSML 要求のすべてのタグを含めて、1,024 文字です。 テキストの言語は、音声フォントの言語と同じである必要があります。

テキスト ボックスに入力して入力モードを確認した後、**[はい]** を選択してテスト要求を送信し、テスト ページに戻ります。 これでテーブルには、新しい要求に対応するエントリと状態の列が表示されます。 音声の合成には数分かかる場合があります。 状態の列に **[Succeeded]\(成功\)** と表示されたら、テキスト入力 (`.txt` ファイル) とオーディオ出力 (`.wav` ファイル) をダウンロードし、後者の品質を試聴できます。

## <a name="create-and-use-a-custom-endpoint"></a>カスタム エンドポイントを作成して使用する

音声モデルの作成とテストが正常に終了したら、カスタム Text-to-Speech エンドポイントに展開します。 その後は、REST API で Text-to-Speech 要求を行うときの通常のエンドポイントの代わりに、このエンドポイントを使います。 カスタム エンドポイントは、フォントを展開するときに使ったサブスクリプションからのみ呼び出すことができます。

新しいカスタム エンドポイントを作成するには、ページ上部の **[Custom Voice]** メニューから **[エンドポイント]** を選択します。 **[展開された音声]** ページが表示され、現在のカスタム音声エンドポイントのテーブルが示されます (存在する場合)。 そのテーブルの 1 行目に現在のロケールが反映されています。 別の言語の展開を作成するには、表示されているロケールを変更します。 (展開しようとしている音声と一致する必要があります。)

新しいエンドポイントを作成するには、**[Deploy voices]\(音声の展開\)** ボタンを選択します。 カスタム エンドポイントの名前と説明を入力します。

**[サブスクリプション]** メニューで、使用するサブスクリプションを選択します。 Free サブスクリプション ユーザーは、一度に 1 つだけモデルを展開できます。 Standard サブスクリプション ユーザーは、それぞれが独自のカスタム音声を使用する最大 20 個のエンドポイントを作成できます。

![エンドポイントを作成する](media/custom-voice/create-endpoint.png)

展開するモデルを選択した後、**[Create]\(作成\)** を選択します。 **[展開された音声]** ページが再び表示され、今回は新しいエンドポイントのエントリがあります。 新しいエンドポイントのインスタンス化には、数分かかることがあります。 展開の状態が **[Succeeded]\(成功\)** の場合、エンドポイントを使用する準備ができています。

![展開された音声](media/custom-voice/my-deployed-voices.png)

展開の状態が **[成功]** である場合は、展開された音声フォントのエンドポイントが **[展開された音声]** テーブルに表示されます。 この URI を HTTP 要求内で直接使用できます。

Custom Voice ポータルを使用して、エンドポイントのオンライン テストを行うこともできます。 エンドポイントをテストするには、**[Custom Voice]** ドロップダウン メニューから **[Endpoints testing]\(エンドポイントのテスト\)** を選択します。 エンドポイントのテスト ページが表示されます。 展開されたカスタム音声を選択し、読み上げるテキストをテキスト ボックスに (プレーンテキストまたは SSML 形式のどちらかで) 入力します。

> [!NOTE] 
> SSML を使用するときは、カスタム音声の作成時に設定した名前を、`<voice>` タグで指定する必要があります。 プレーン テキストを送信する場合は、常にカスタム音声が使用されます。

カスタム音声フォントで読み上げられるテキストを聞くには、**[Play]\(再生\)** を選択します。

![エンドポイント テスト](media/custom-voice/endpoint-testing.png)

カスタム エンドポイントの機能は、テキスト読み上げ要求に使用される標準のエンドポイントと同じです。 詳しくは、[REST API](rest-apis.md) に関するページをご覧ください。

## <a name="language-support"></a>言語のサポート

音声のカスタマイズは、米国英語 (en-US)、本土中国語 (zh-CN)、およびイタリア語 (it-IT) で使用できます。

> [!NOTE]
> イタリア語の音声トレーニングは、2,000 件以上の発話のデータ セットから始まります。 中国語と英語のバイリンガル モデルも、2,000 件以上の発話のデータ セットでサポートされています。

## <a name="next-steps"></a>次の手順

- [Speech 試用版サブスクリプションを取得する](https://azure.microsoft.com/try/cognitive-services/)
- [音声サンプルを録音する](record-custom-voice-samples.md)
