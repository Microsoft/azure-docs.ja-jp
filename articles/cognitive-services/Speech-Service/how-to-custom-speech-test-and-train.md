---
title: Custom Speech 用のデータを準備する - Speech サービス
titleSuffix: Azure Cognitive Services
description: マイクロソフトの音声認識の正確性をテストする場合、またはカスタム モデルをトレーニングする場合は、オーディオ データとテキスト データが必要です。 このページでは、データ型、使用方法、および管理方法について説明します。
services: cognitive-services
author: trevorbye
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 03/27/2020
ms.author: trbye
ms.openlocfilehash: f43f7894c46a75894eb648f02ec378f3a8b2633d
ms.sourcegitcommit: d7fba095266e2fb5ad8776bffe97921a57832e23
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/09/2020
ms.locfileid: "84628046"
---
# <a name="prepare-data-for-custom-speech"></a>Custom Speech 用のテスト データを準備する

マイクロソフトの音声認識の正確性をテストする場合、またはカスタム モデルをトレーニングする場合は、オーディオ データとテキスト データが必要です。 このページでは、カスタム音声モデルで必要とするデータの種類について説明します。

## <a name="data-diversity"></a>データの多様性

カスタム モデルをテストしてトレーニングするために使用するテキストとオーディオには、モデルに認識させる必要がある多様なスピーカーとシナリオのセットからのサンプルが含まれている必要があります。
カスタム モデルのテストとトレーニングのためにデータを収集する場合は、次の要素を考慮してください。

* テキストと音声オーディオ データでは、モデルを操作するときにユーザーが行う口頭のステートメントの種類をカバーする必要があります。 たとえば、温度を上げ下げするモデルでは、ユーザーがそのような変更を要求するために作成するステートメントに関してトレーニングする必要があります。
* データには、モデルで認識する必要があるすべての音声の差異を含める必要があります。 アクセント、方言、言語の混在、年齢、性別、音声ピッチ、ストレス レベル、時刻など、多くの要因によって音声が異なる可能性があります。
* モデルが使用されるさまざまな環境 (屋内、屋外、交通騒音) からのサンプルを含める必要があります。
* オーディオは、実稼働システムで使用するハードウェア デバイスを使用して収集する必要があります。 モデルで、さまざまな品質の記録デバイスで記録された音声を識別する必要がある場合は、モデルをトレーニングするために提供するオーディオ データでも、これらの多様なシナリオを表している必要があります。
* 後でモデルにデータを追加することもできますが、データセットの多様性とプロジェクトのニーズの表現を維持するように注意してください。
* カスタム モデル認識のニーズの範囲に*ない*データを含めると、認識品質全体に害を及ぼす可能性があるため、モデルで文字起こしする必要がないデータは含めないでください。

シナリオのサブセットでトレーニングされたモデルは、それらのシナリオでのみ適切に実行できます。 カスタム モデルで認識する必要があるシナリオの完全な範囲を表すデータを慎重に選択します。

> [!TIP]
> モデルで検出される言語と音響に一致する小さなサンプル データのセットから始めます。
> たとえば、実稼働シナリオでモデルが検出する同じハードウェアと同じ音響環境で、小さいが代表的なオーディオのサンプルを記録します。
> トレーニング用にはるかに大きなデータセットの収集に投資する前に、代表的なデータの小さなデータセットで、問題点を明らかにできます。

## <a name="data-types"></a>データ型

この表には、許容されるデータの種類と、それぞれのデータの種類を使用する場合と推奨される数量が一覧表示されています。 モデルを作成するのに、すべてのデータの種類は必要ありません。 データ要件は、テストを作成するのか、またはモデルをトレーニングするのかによって異なります。

| データ型 | テストに使用 | 推奨数量 | トレーニングに使用 | 推奨数量 |
|-----------|-----------------|----------|-------------------|----------|
| [オーディオ](#audio-data-for-testing) | はい<br>目視検査に使用 | 5 つ以上のオーディオ ファイル | いいえ | 該当なし |
| [オーディオ + 人間というラベルが付いたトランスクリプト](#audio--human-labeled-transcript-data-for-testingtraining) | はい<br>精度を評価するために使用 | 0.5-5 時間のオーディオ | はい | 1 - 1,000 時間のオーディオ |
| [関連するテキスト](#related-text-data-for-training) | いいえ | 該当なし | はい | 1 - 200 MB の関連テキスト |

ファイルは、型別にデータセットにグループ化し、ZIP ファイルとしてアップロードする必要があります。 各データセットには、1 つのデータの種類のみを含めることができます。

> [!TIP]
> すぐに始めるには、サンプルデータの使用を検討してください。 <a href="https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/sampledata/customspeech" target="_target">サンプル Custom Speech データ <span class="docon docon-navigate-external x-hidden-focus"></span></a>については、こちらの GitHub リポジトリを参照する

## <a name="upload-data"></a>データのアップロード

データをアップロードするには、<a href="https://speech.microsoft.com/customspeech" target="_blank">Custom Speech ポータル <span class="docon docon-navigate-external x-hidden-focus"></span></a>に移動します。 ポータルで、 **[データのアップロード]** をクリックしてウィザードを起動し、最初のデータセットを作成します。 データのアップロードが許可される前に、データセットにより音声データ型を選択するように求められます。

![Speech ポータルからオーディオを選択する](./media/custom-speech/custom-speech-select-audio.png)

アップロードする各データセットでは、選択したデータの種類の要件が満たされている必要があります。 アップロードする前に、データの書式を正しく設定する必要があります。 データが正しくフォーマットされていれば、Custom Speech サービスによって正確に処理されます。 要件は、以降のセクションに示されています。

データセットをアップロードした後は、いくつかの選択肢があります。

* **[テスト]** タブに移動して、オーディオのみまたはオーディオ + 人間というラベルが付いた文字起こしデータを目視で検査できます。
* **[トレーニング]** タブに移動し、オーディオ + 人間の文字起こしデータまたは関連するテキスト データを使用して、カスタム モデルをトレーニングできます。

## <a name="audio-data-for-testing"></a>テスト用のオーディオ データ

オーディオ データは、Microsoft の基準の音声テキスト変換モデルやカスタム モデルの精度をテストするのに最適です。 オーディオ データは、特定のモデルのパフォーマンスに関する音声の精度を検査するために使用されることに注意してください。 モデルの精度の定量化を検討している場合は、[オーディオ + 人間というラベルが付いた文字起こしデータ](#audio--human-labeled-transcript-data-for-testingtraining)を使用します。

次の表を使用して、Custom Speech で使用するためにオーディオ ファイルが確実に正しく書式設定されるようにします。

| プロパティ                 | 値                 |
|--------------------------|-----------------------|
| ファイル形式              | RIFF (WAV)            |
| サンプル レート              | 8,000 Hz または 16,000 Hz |
| チャンネル                 | 1 (モノラル)              |
| オーディオあたりの最大長 | 2 時間               |
| サンプル形式            | PCM、16 ビット           |
| アーカイブ形式           | .zip                  |
| 最大アーカイブ サイズ     | 2 GB                  |

[!INCLUDE [supported-audio-formats](includes/supported-audio-formats.md)]

> [!TIP]
> トレーニング データとテスト データをアップロードする場合、.zip ファイルのサイズは 2 GB を超えることはできません。 トレーニング用にさらに多くのデータが必要な場合は、複数の .zip ファイルに分割し、個別にアップロードします。 その後、*複数* のデータセットからトレーニングを選択できます。 ただし、*単一* のデータセットからのみテストができます。

<a href="http://sox.sourceforge.net" target="_blank" rel="noopener">SoX <span class="docon docon-navigate-external x-hidden-focus"></span></a> を使用して、オーディオのプロパティを確認したり、既存のオーディオを適切な形式に変換したりします。 SoX のコマンドラインから、これらのアクティビティ各々を実行する方法の例を、次にいくつか示します:

| アクティビティ | 説明 | SoX コマンド |
|----------|-------------|-------------|
| オーディオ形式の確認 | このコマンドを使用して確認<br>オーディオ ファイル形式。 | `sox --i <filename>` |
| オーディオの形式の変換 | このコマンドを使用して変換<br>オーディオファイルは、シングルチャネル、16 ビット、16 KHz です。 | `sox <input> -b 16 -e signed-integer -c 1 -r 16k -t wav <output>.wav` |

## <a name="audio--human-labeled-transcript-data-for-testingtraining"></a>テスト/トレーニング用のオーディオ + 人間というラベルが付いた文字起こしデータ

オーディオ ファイルを処理するときに、Microsoft の音声テキスト変換の精度を測定するには、比較のため、人間というラベルが付いた文字起こし (単語単位) を提供する必要があります。 多くの場合、人間というラベルが付いた文字起こしには時間がかかりますが、ユース ケースのモデルの精度を評価およびトレーニングするために必要です。 認識の向上は、提供されたデータによって決まることに注意してください。 そのため、高品質なトランスクリプトのみをアップロードすることが重要です。

オーディオ ファイルには、録音の最初と最後に無音部分が含まれている場合があります。 可能であれば、各サンプル ファイルの音声の前後に少なくとも 0.5 秒の無音部分を含めます。 音量が小さかったり、邪魔な背景ノイズが入っていたりするオーディオは役に立ちませんが、カスタム モデルが損なわれることはありません。 オーディオ サンプルを収集する前に、マイクと信号処理ハードウェアのアップグレードを常に検討してください。

| プロパティ                 | 値                               |
|--------------------------|-------------------------------------|
| ファイル形式              | RIFF (WAV)                          |
| サンプル レート              | 8,000 Hz または 16,000 Hz               |
| チャンネル                 | 1 (モノラル)                            |
| オーディオあたりの最大長 | 2 時間 (テスト) / 60 分 (トレーニング) |
| サンプル形式            | PCM、16 ビット                         |
| アーカイブ形式           | .zip                                |
| Zip の最大サイズ         | 2 GB                                |

[!INCLUDE [supported-audio-formats](includes/supported-audio-formats.md)]

> [!NOTE]
> トレーニング データとテスト データをアップロードする場合、.zip ファイルのサイズは 2 GB を超えることはできません。 *単一* のデータセットからのみテストできます。確認して、適切なファイルサイズで保持するようにしてください。 また、各トレーニング ファイルは 60 秒を超えることはできません。超えてしまうと、エラーが発生します。

単語の削除や置換のような問題に対処するには、認識を向上させるために大量のデータが必要です。 一般に、約 10 から 1,000 時間分のオーディオについて単語単位の文字起こしを提供することをお勧めします。 すべての WAV ファイルの文字起こしは、1 つのプレーン テキスト ファイルに格納されている必要があります。 文字起こしファイルの各行には、いずれかのオーディオ ファイルの名前に続けて、対応する文字起こしが含まれている必要があります。 ファイル名と文字起こしは、タブ (\t) で区切る必要があります。

  次に例を示します。
```
  speech01.wav  speech recognition is awesome
  speech02.wav  the quick brown fox jumped all over the place
  speech03.wav  the lazy dog was not amused
```

> [!IMPORTANT]
> 文字起こしは、UTF-8 バイト オーダー マーク (BOM) としてエンコードされている必要があります。

文字起こしに対しては、システムによって処理できるように、テキストの正規化が行われます。 ただし、データを Speech Studio にアップロードする前に実行する必要がある重要な正規化がいくつかあります。 文字起こしを準備する際に使用する適切な言語については、「[How to create a human-labeled transcription](how-to-custom-speech-human-labeled-transcriptions.md)」(人間とラベル付けされた文字起こしの作成方法) を参照してください。

オーディオ ファイルと対応する文字起こしを収集した後、<a href="https://speech.microsoft.com/customspeech" target="_blank">Custom Speech ポータル <span class="docon docon-navigate-external x-hidden-focus"></span></a>にアップロードする前に、それらを1つの .zip ファイルとしてパッケージ化します。 3 つのオーディオ ファイルと、人間とラベル付けされた文字起こしファイルを含むデータセットの例を示します:

> [!div class="mx-imgBorder"]
> ![Speech ポータルからオーディオを選択する](./media/custom-speech/custom-speech-audio-transcript-pairs.png)

## <a name="related-text-data-for-training"></a>トレーニング用の関連するテキスト データ

製品名または固有の機能には、トレーニング用の関連テキストデータが含まれている必要があります。 関連テキストは、正しい認識を保証するのに役立ちます。 認識を向上させるため、次の 2 種類の関連するテキスト データを提供することができます。

| データ型 | このデータによりどのように認識が向上するか |
|-----------|------------------------------------|
| 文 (発話) | 製品名を認識する場合や、文のコンテキスト内で業界固有の語彙を認識する場合の精度を向上させます。 |
| 発音 | 一般的でない用語、略語、またはその他の発音が定義されていない単語の発音を向上させることができます。 |

発話は、1 つまたは複数のテキスト ファイルとして提供できます。 正確性を高めるには、読み上げられる発話に近いテキスト データを使用します。 発音は、1 つのテキスト ファイルとして指定する必要があります。 すべてを 1つの zip ファイルとしてパッケージ化し、<a href="https://speech.microsoft.com/customspeech" target="_blank">Custom Speech ポータル <span class="docon docon-navigate-external x-hidden-focus"></span></a>にアップロードできます。

### <a name="guidelines-to-create-a-sentences-file"></a>発話ファイルを作成するためのガイドライン

関連する文を使用してカスタム モデルを作成するには、サンプルの発話の一覧を提供する必要があります。 発話は、完全または文法的に正しい_必要はありません_が、運用環境で期待される音声入力を正確に反映する必要があります。 特定の用語の重みを付けるには、これらの特定の用語を含む複数の文を追加します。

一般的なガイダンスとして、モデル適応は、トレーニングテキストが運用環境で予想される実際のテキストにできるだけ近い場合に最も効果的です。 強化する対象として、ドメイン固有の用語や語句をトレーニングテキストに含める必要があります。 可能であれば、1つの文またはキーワードを別の行に制御してみてください。 ユーザーにとって重要なキーワードと語句 (製品名など) は、数回コピーできます。 しかし、コピーしすぎないでください。これは、全体的な認識率に影響する可能性があります。

この表を使用して、発話の関連するデータ ファイルが確実に正しく書式設定されるようにします。

| プロパティ | 値 |
|----------|-------|
| テキストのエンコード | UTF-8 BOM |
| 1 行あたりの発話の数 | 1 |
| ファイルの最大サイズ | 200 MB |

さらに、次の制限を考慮します。

* 文字を 5 回以上繰り返さないようにします。 例: "aaaa" や "uuuu"。
* 特殊文字または 上記 `U+00A1` の UTF-8 文字は使用しないでください。
* URI は拒否されます。

### <a name="guidelines-to-create-a-pronunciation-file"></a>発音ファイルを作成するためのガイドライン

ユーザー側で発生するまたは使用する可能性がある、標準の発音がない一般的でない用語がある場合は、カスタム発音ファイルを提供して認識を向上させることができます。

> [!IMPORTANT]
> カスタムの発音ファイルを使用して、共通単語の発音を変更することはお勧めしません。

これには、音声発話の例と、それぞれのカスタム発音が含まれます。

| 認識される/表示されるフォーム | 音声フォーム |
|--------------|--------------------------|
| 3CPO | three c p o |
| CNTK | c n t k |
| IEEE | i triple e |

音声フォームは、スペル アウトされた表示フォームの音声シーケンスです。これは文字、単語、音節、または 3 つすべての組み合わせで構成できます。

カスタマイズされた発音は、英語 (`en-US`) およびドイツ語 (`de-DE`) で使用できます。 この表に、言語ごとにサポートされている文字を示します。

| Language | Locale | 文字 |
|----------|--------|------------|
| 英語 | `en-US` | `a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z` |
| ドイツ語 | `de-DE` | `ä, ö, ü, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z` |

次の表を使用して、発音用の関連データ ファイルが正しく書式設定されているか確認します。 発音ファイルは小さいため、数キロバイトしかサイズは必要ありません。

| プロパティ | 値 |
|----------|-------|
| テキストのエンコード | UTF-8 BOM (英語では ANSI もサポートされています) |
| 1 行のあたりの発音数 | 1 |
| ファイルの最大サイズ | 1 MB (Free レベルに 1 KB) |

## <a name="next-steps"></a>次のステップ

* [データを検査する](how-to-custom-speech-inspect-data.md)
* [データを評価する](how-to-custom-speech-evaluate-data.md)
* [モデルをトレーニングする](how-to-custom-speech-train-model.md)
* [モデルをデプロイする](how-to-custom-speech-deploy-model.md)
