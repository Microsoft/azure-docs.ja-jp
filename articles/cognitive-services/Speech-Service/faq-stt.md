---
title: Azure の音声テキスト変換についてよく寄せられる質問
titleSuffix: Azure Cognitive Services
description: 音声テキスト変換に関してよく寄せられる質問に対する回答を紹介します。
services: cognitive-services
author: PanosPeriorellis
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 07/05/2019
ms.author: panosper
ms.openlocfilehash: bde68a70ac047433e86b7e06bc5f4a56bdd28595
ms.sourcegitcommit: 11265f4ff9f8e727a0cbf2af20a8057f5923ccda
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/08/2019
ms.locfileid: "72028500"
---
# <a name="speech-to-text-frequently-asked-questions"></a>音声テキスト変換についてよく寄せられる質問

疑問点への回答がこのよく寄せられる質問で見つからない場合は、[その他のサポート オプション](support.md)を確認してください。

## <a name="general"></a>全般

**Q:音声テキスト変換のベースライン モデルとカスタム音声テキスト変換の違いは何ですか。**

**A**: ベースライン モデルは Microsoft 所有のデータを使用してトレーニングされており、事前にクラウドにデプロイされています。  カスタム モデルを使用すると、特定のアンビエント ノイズまたは言語がある特定の環境にさらに合うようにモデルを調整できます。 工場の現場、車の中、または騒音の多い道路などでは、適合させた音響モデルが必要です。 生物学、物理学、放射線学、製品名、およびカスタムの頭字語などのトピックには、適合させた言語モデルが必要になることがあります。

**Q:ベースライン モデルの使用はどこから開始できますか。**

**A**: 最初に、[サブスクリプション キー](get-started.md)を取得します。 事前にデプロイされたベースライン モデルに対して REST 呼び出しを実行する方法については、「[REST API](rest-apis.md)」を参照してください。 WebSocket を使用する場合は、[SDK](speech-sdk.md) をダウンロードしてください。

**Q:カスタム音声モデルを常にビルドする必要はありますか。**

**A**: No. アプリケーションが一般的な日常の言語を使用している場合、モデルをカスタマイズする必要はありません。 アプリケーションが背景ノイズのほんとどない環境で使用されている場合も、モデルをカスタマイズする必要はありません。

ベースライン モデルとカスタマイズしたモデルをポータルでデプロイし、それらに対して正確性テストを実行できます。 この機能を使用して、ベースライン モデルとカスタム モデルの正確性を測定して比較できます。

**Q:データセットまたはモデルの処理が完了した場合にはそれをどのように知ることができますか。**

**A**: 現在、それを知る唯一の方法はテーブル内のモデルやデータ セットの状態です。 処理が完了すると、その状態は **[成功]** になります。

**Q:複数のモデルを作成できますか。**

**A**: コレクション内のモデル数に制限はありません。

**Q:ミスをしてしまったことに気付きました。進行中のデータのインポートやモデルの作成をキャンセルするにはどうすればよいですか。**

**A**: 現在、音響モデルや言語モデルの適応処理はロールバックできません。 インポートされたデータやモデルは、終了状態になれば削除できます。

**Q:検索およびディクテーション モデルと会話モデルの違いは何ですか。**

**A**: 音声サービスでは、複数のベースライン モデルから選択できます。 Conversational モデルは、会話形式で話される音声の認識に役立ちます。 このモデルは、電話の内容を文字起こしするのに最適です。 検索およびディクテーション モデルは、音声によってトリガーされるアプリに最適です。 Universal モデルは、両方のシナリオへの対処を目的にした新しいモデルです。 Universal モデルは現在、ほとんどのロケールで Conversational モデルの品質レベル以上です。

**Q:既存のモデル (モデル スタッキング) を更新できますか。**

**A**: 既存のモデルは更新できません。 解決策として、以前のデータセットを新しいデータセットと結合し、新たに調整してください。

古いデータセットと新しいデータセットは、単一の .zip ファイル (音響データの場合) または .txt ファイル (言語データの場合) に組み合わせて使用する必要があります。 適応が完了したら、新しいエンドポイントを取得するために、新しく更新されたモデルのデプロイを解除する必要があります

**Q:新しいバージョンのベースラインが利用可能な場合は、デプロイは自動的に更新されますか。**

**A**: デプロイは自動的には更新されません。

ベースライン V1.0 でモデルをデプロイしている場合、そのデプロイはそのまま残ります。 顧客はデプロイ済みのモデルを解除し、新しいバージョンのベースラインを使用して再調整し、再デプロイできます。

**Q:デプロイしたモデルに、ポータルで提供されているものより高いコンカレンシーが必要な場合はどうすればよいですか。**

**A**: モデルは同時要求を 20 ずつ処理するようスケールアップできます。

より高いスケールが必要な場合は、[音声のサポート](mailto:speechsupport@microsoft.com?subject=Request%20for%20higher%20concurrency%20for%20Speech-to-text)にお問い合わせください。

**Q:自分のモデルをダウンロードしてローカルで実行できますか。**

**A**: モデルをダウンロードしてローカルで実行することはできません。

**Q:個人の要求はログに記録されますか。**

**A**: トレースをオフに切り替えるデプロイを作成する場合には、選択肢があります。 その時点では、音声または文字起こしは記録されません。 そうしない場合、通常は Azure のセキュリティで保護された記憶域に要求のログが記録されます。

**Q:ユーザーの要求は調整されますか。**

**A**: REST API では、要求を 5 秒で 25 に制限しています。 詳細は、[音声テキスト変換](speech-to-text.md)に関するページを参照してください。

**Q:デュアル チャネル オーディオの料金はどのように課金されますか。**

**A**: 各チャネルを個別に送信した場合 (各チャネルは独自のファイルにあります)、各ファイルの期間ごとに課金されます。 各チャネルを多重化して 1 つのファイルを送信すると、1 つのファイルの期間に対して課金されます。

> [!IMPORTANT]
> Custom Speech Service の使用について他にプライバシーに関する懸念がある場合は、いずれかのサポート チャネルにお問い合わせください。

## <a name="importing-data"></a>データのインポート

**Q:データセットのサイズの制限とは何ですか、なぜ制限するのですか。**

**A**: データセットの現在の制限は 2 GB です。 この制限は、HTTP のアップロード用のファイルのサイズに対する制限が原因です。 

**Q:テキスト ファイルを zip で圧縮すればさらに大きなテキスト ファイルをアップロードできるでしょうか。** 

**A**: No. 現時点では圧縮されていないテキスト ファイルのみが許可されます。

**Q:データ レポートが発話にエラーがあったと示しています。どのような問題が発生していますか。** "

**A**: ファイル内の発話の 100% をアップロードできなくても問題ありません。 音響または言語データセット内の発話の大多数 (95% 以上など) が正常にインポートされた場合、そのデータセットは使用可能と見なされます。 ただし、発話でエラーが発生した原因を理解してその問題を修正するよう試行することをお勧めします。 フォーマット エラーなどの一般的な問題は簡単に修正できます。 

## <a name="creating-an-acoustic-model"></a>音響モデルの作成

**Q:どれくらいの量の音響データが必要ですか。**

**A**: 30 分から 1 時間分の音響データとの間で始まることをお勧めします。

**Q:どのようなデータを収集したほうがよいですか。**

**A**: できるだけアプリケーションのシナリオやユースケースに近いデータを収集してください。 データ コレクションはデバイス、環境、話者の種類の点でターゲット アプリケーションやユーザーと一致している必要があります。 一般的に、できるだけ広範囲の話者からデータを収集することをお勧めします。 

**Q:音響データはどのように収集しますか。**

**A**: スタンドアロンのデータ コレクション アプリケーションを作成するか、既製の録音ソフトウェアを使用できます。 また、オーディオ データを記録してそれを使用するバージョンのアプリケーションを作成することもできます。 

**Q:適応データを自分で文字に起こす必要はありますか。**

**A**: はい。 ご自身で文字に起こすか、プロの文字起こしサービスを利用してください。 プロの筆記者を好むユーザーもいれば、クラウドソーシングを使用したり、または自分で文字起こししたりするユーザーもいます。

## <a name="accuracy-testing"></a>正確性のテスト

**Q:カスタム言語モデルを使用してカスタム音響モデルのオフライン テストを実行できますか。**

**A**: はい。オフライン テストを設定するときにドロップダウン メニューからカスタム言語モデルを選択するだけです。

**Q:カスタム音響モデルを使用してカスタム言語モデルのオフライン テストを実行できますか。**

**A**: はい。オフライン テストを設定するときにドロップダウン メニューからカスタム音響モデルを選択するだけです。

**Q:ワード エラー率 (WER) とは何ですか。また、どのように計算されますか。**

**A**: WER は、音声認識の評価メトリックです。 WER はエラー (挿入、削除、置換など) の合計数から、参照する文字起こしの合計ワード数を除算して計算されます。 詳細については、[ワード エラー率](https://en.wikipedia.org/wiki/Word_error_rate)をご覧ください。

**Q:正確性テストの結果が良好であることはどのように判断すればよいですか。**

**A**: 結果はベースライン モデルとカスタマイズしたモデルの比較を示します。 カスタマイズをそれだけの価値があるものにするには、ベースライン モデルを上回ることを目標にすべきです。

**Q:改善があったかどうかを知るためにベース モデルの WER はどのように確認できますか。** 

**A**: オフライン テストの結果は、カスタム モデルのベースライン精度、およびベースラインからの改善を示します。

## <a name="creating-a-language-model"></a>言語モデルの作成

**Q:アップロードする必要があるテキスト データの量はどれくらいですか。**

**A**: アプリケーションで使用されているボキャブラリやフレーズが最初の言語モデルとどれくらい異なるかによって変わります。 すべての新しいワードについて、それらのワードの使用法の例をできるだけ多く提供すると便利です。 アプリケーションに使用されている一般的なフレーズについては、言語データにフレーズを含めると、システムにそれらの用語もリッスンするよう伝えるため、便利です。 言語データセットには最低でも 100、通常は数百以上の発話があることが一般的です。 また、ある種類 のクエリが他よりも一般的である場合、その一般的なクエリの複数のコピーをデータセットに挿入できます。

**Q:単語のリストをアップロードできますか。**

**A**: 単語のリストをアップロードすると、それらの単語はボキャブラリに追加されますが、それらの単語の一般的な使用方法はシステムに伝わりません。 すべての発話または発話の一部 (ユーザーが言いそうな文や語句) を指定すると、言語モデルはその新しい単語とその使用方法を学習します。 カスタム言語モデルは、システムに新しい単語を追加するだけでなく、新しいアプリケーションに対して既知の単語の確度を調整するのに便利です。 すべての発話を指定すると、システムがより学習できるようになります。 

## <a name="next-steps"></a>次の手順

* [トラブルシューティング](troubleshooting.md)
* [リリース ノート](releasenotes.md)
