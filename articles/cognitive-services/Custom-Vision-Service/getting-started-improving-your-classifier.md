---
title: 分類子の改善 - Custom Vision Service
titlesuffix: Azure Cognitive Services
description: 分類子の品質を改善する方法について説明します。
services: cognitive-services
author: patrickfarley
manager: nitinme
ms.service: cognitive-services
ms.subservice: custom-vision
ms.topic: conceptual
ms.date: 03/21/2019
ms.author: pafarley
ms.openlocfilehash: 35f83832b0ceb7507b39095e9cc974d82a480c69
ms.sourcegitcommit: 41ca82b5f95d2e07b0c7f9025b912daf0ab21909
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/13/2019
ms.locfileid: "60606935"
---
# <a name="how-to-improve-your-classifier"></a>分類子を改善する方法

このガイドでは、Custom Vision Service 分類子の品質を改善する方法について説明します。 分類子の品質は、そこに提供するラベル付きデータの量、品質、多様性や、データセット全体のバランスがどれだけとれているかに依存します。 適切な分類子には、その分類子に送信されるものを代表する、バランスのとれたトレーニング データセットがあります。 このような分類子を構築するプロセスは反復的です。予想される結果に到達するために、数回のトレーニングが必要になることが一般的です。

より正確な分類子の構築に役立つ一般的なパターンを次に示します。

1. 1 回目のトレーニング
1. さらに画像を追加し、データのバランスをとる。再トレーニング
1. 背景、照明、オブジェクト サイズ、カメラ アングル、スタイルがさまざまな画像を追加する。再トレーニング
1. 新しい画像を使用して予測をテストする
1. 予測結果に従って、既存のトレーニング データを変更する

## <a name="prevent-overfitting"></a>オーバーフィットを防ぐ

分類子は、画像が共通して持つ任意の特性に基づいて予測を行うことを学習することがあります。 たとえば、リンゴと柑橘類を区別する分類子を作成しており、手の中のリンゴの画像と白いお皿の上の柑橘類の画像を使用している場合、その分類子はリンゴと柑橘類ではなく、手と白いお皿を不当に重視することがあります。

![予期しない分類の画像](./media/getting-started-improving-your-classifier/unexpected.png)

この問題を修正するには、より多様な画像を使用したトレーニングに関する次のガイダンスを使用し、さまざまなアングル、背景、オブジェクト サイズ、グループ、およびその他の変種を含む画像を提供します。

## <a name="data-quantity"></a>データの数量

トレーニング画像の数は、最も重要な要素です。 開始点としてラベルごとに少なくとも 50 個の画像を使用することをお勧めします。 画像が少ないほど、オーバー フィットのリスクが高くなり、パフォーマンスの数値は良い品質を示すことがありますが、実際のデータの処理に苦労する可能性があります。 

## <a name="data-balance"></a>データのバランス

トレーニング データの相対量を考慮することも重要です。 たとえば 1 つのラベルに 500 個の画像を使用し、別のラベルに 50 個の画像を使用すると、不均衡なトレーニング データセットになります。 これにより、あるラベルが他のラベルより、モデルの予測が正確になります。 画像が最も少ないラベルと画像が最も多いラベルの間で少なくとも 1:2 の比率を維持すれば、より優れた結果が得られる可能性があります。 たとえば、画像が最も多いラベルに 500 個の画像がある場合、画像が最も少ないラベルにはトレーニングのために少なくとも 250 個の画像が必要です。

## <a name="data-variety"></a>データの多様性

通常の使用中に分類子に送信されるものを代表する画像を使用してください。 そうしないと、分類子は、画像が共通して持つ任意の特性に基づいて予測を行うように学習する可能性があります。 たとえば、リンゴと柑橘類を区別する分類子を作成しており、手の中のリンゴの画像と白いお皿の上の柑橘類の画像を使用している場合、その分類子はリンゴと柑橘類ではなく、手と白いお皿を不当に重視することがあります。

![予期しない分類の画像](./media/getting-started-improving-your-classifier/unexpected.png)

この問題を解決するには、多様な画像を含めて、分類子が十分に汎用化できるようにします。 トレーニング セットをより多様にするために実行できるいくつかの方法を次に示します。

* __背景:__ さまざまな背景の前のオブジェクトの画像を提供します。 自然な背景の写真は、分類子により詳細な情報を提供するため、無彩色の背景の写真より優れています。

    ![背景のサンプルの画像](./media/getting-started-improving-your-classifier/background.png)

* __照明:__ 特に、予測に使用される画像にさまざまな照明が含まれている場合は、照明が多様な (たとえば、フラッシュで撮られた、露出が高いなど) 画像を提供します。 これはまた、彩度、色相、および輝度が多様な画像を使用するためにも役立ちます。

    ![照明のサンプルの画像](./media/getting-started-improving-your-classifier/lighting.png)

* __オブジェクト サイズ:__ オブジェクトのサイズと数がさまざまに異なる画像を提供します (1 束のバナナや 1 本のバナナのクローズ アップの写真など)。 さまざまなサイズは、分類子がより適切に一般化するのに役立ちます。

    ![サイズのサンプルの画像](./media/getting-started-improving-your-classifier/size.png)

* __カメラ アングル:__ さまざまなカメラ アングルで撮られた画像を提供します。 または、すべての写真が固定されたカメラ (防犯カメラなど) で撮る必要がある場合は、オーバーフィット、つまり関連のないオブジェクト (街灯柱など) を重要な特徴として解釈することを回避するために、定期的に発生するオブジェクトごとに、異なるラベルを割り当てるようにしてください。

    ![アングルのサンプルの画像](./media/getting-started-improving-your-classifier/angle.png)

* __スタイル:__ 同じクラスの異なるスタイル (同じ果物の異なる種類など) の画像を提供します。 ただし、スタイルが極端に異なるオブジェクトの画像 (たとえば、ミッキー マウスに対して実物のネズミ) がある場合は、その個別の特徴をより適切に表すために、それらに別のクラスとしてラベルを付けることをお勧めします。

    ![スタイルのサンプルの画像](./media/getting-started-improving-your-classifier/style.png)

## <a name="negative-images"></a>否定画像

分類子をより正確にする助けになるように、プロジェクトのある時点で、_否定的サンプル_の追加が必要になることがあります。 否定的サンプルとは、それ以外のどのタグとも一致しないタグです。 これらの画像をアップロードするときには、画像に特殊な **否定用** ラベルを適用します。

> [!NOTE]
> Custom Vision Service サービスは、イメージの自動否定処理をいくつかサポートしています。 たとえば、ブドウとバナナを区別する分類子を構築しており、予測のために片方の靴の画像を送信した場合、その分類子はブドウとバナナの両方について、その画像に 0% に近いスコアを付けるはずです。
> 
> これに対して、否定画像がトレーニングで使用された画像の変動にすぎない場合は、その大きな類似点のために、モデルがその否定画像をラベル付きのクラスとして分類する可能性があります。 たとえば、オレンジとグレープフルーツを区別する分類子があり、クレメンタインの画像を取り込んだ場合、クレメンタインの多くの特徴がオレンジの特徴と似ているため、その分類子はクレメンタインにオレンジとしてスコアを付ける可能性があります。 否定画像がこれと同じ性質である場合は、1 つ以上の追加のタグ (**その他**など) を作成し、トレーニング中に否定画像にこのタグのラベルを付けて、モデルがこれらのクラスをより適切に区別できるようにすることをお勧めします。

## <a name="use-prediction-images-for-further-training"></a>追加のトレーニングに予測画像を使用する

予測エンドポイントにイメージを送信することによって、画像分類子を使用またはテストすると、Custom Vision サービスによって、それらの画像が格納されます。 それらを使用して、モデルを改善できます。

1. 分類子に送信された画像を表示するには、[Custom Vision Web ページ](https://customvision.ai)を開き、プロジェクトに移動して __[予測]__ タブを選択します。既定のビューには、現在のイテレーションのイメージが表示されます。 __[Iteration]\(イテレーション\)__ ドロップ ダウン メニューを使用すると、以前のイテレーションで送信されたイメージを表示できます。

    ![ビュー内に画像がある予測タブのスクリーン ショット](./media/getting-started-improving-your-classifier/predictions.png)

2. イメージの上にポインターを置き、分類子が予測したタグを表示します。 分類子を最も改善できる画像が一番上に一覧表示されるように、画像が並べ替えられます。 さまざまな並べ替え方法を使用するには、 __[並べ替え]__ セクションで選択します。 

    既存のトレーニング データに画像を追加するには、画像を選択し、正しいタグを設定して __[保存して閉じる]__ をクリックします。 画像が __[予測]__ から削除され、一連のトレーニング画像に追加されます。 __[Training Images]__ (トレーニング イメージ) タブを選択すると、これを表示できます。

    ![タグ付けページのイメージ](./media/getting-started-improving-your-classifier/tag.png)

3. 次に、 __[トレーニング]__ ボタンを使用して、分類子を再トレーニングします。

## <a name="visually-inspect-predictions"></a>予測を視覚的に検査する

画像の予測を検査するには、 __[Training Images]\(トレーニング イメージ\)__ タブで、 **[Iteration]\(イテレーション\)** ドロップダウン メニューから以前のトレーニング イテレーションを選択し、 **[タグ]** セクションで 1 つまたは複数のタグをチェックします。 ビューでは、モデルが特定のタグを正しく予測できなかった各画像の周囲に赤いボックスが表示されているはずです。

![イテレーション履歴のイメージ](./media/getting-started-improving-your-classifier/iteration.png)

視覚的な検査により、その後でさらにトレーニング データを追加するか、または既存のトレーニング データを変更することによって修正できるパターンを識別できる場合があります。 たとえば、リンゴとライムを区別する分類子によって、すべての緑色のリンゴに誤ってライムとしてラベルが付けられる可能性があります。 この問題は、緑色のリンゴのタグ付きの画像を含むトレーニング データを追加および提供することによって修正できます。

## <a name="next-steps"></a>次の手順

このガイドでは、カスタム画像分類モデルをより正確にするためのいくつかの技法について説明しました。 次に、画像を予測 API に送信することによって、それらの画像をプログラムでテストする方法を説明します。

> [!div class="nextstepaction"]
> [予測 API の使用](use-prediction-api.md)
