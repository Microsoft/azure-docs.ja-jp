---
title: "Azure Service Fabric のディザスター リカバリー | Microsoft Docs"
description: "Azure Service Fabric では、あらゆる種類の災害に対処するために必要な機能が提供されています。 この記事では、発生する可能性がある災害の種類とそれらに対処する方法について説明します。"
services: service-fabric
documentationcenter: .net
author: masnider
manager: timlt
editor: 
ms.assetid: ab49c4b9-74a8-4907-b75b-8d2ee84c6d90
ms.service: service-fabric
ms.devlang: dotNet
ms.topic: article
ms.tgt_pltfrm: NA
ms.workload: NA
ms.date: 08/18/2017
ms.author: masnider
ms.translationtype: HT
ms.sourcegitcommit: 847eb792064bd0ee7d50163f35cd2e0368324203
ms.openlocfilehash: f50d5073b0016bbf0c7b6ba1374e951225dfd88f
ms.contentlocale: ja-jp
ms.lasthandoff: 08/19/2017

---
# <a name="disaster-recovery-in-azure-service-fabric"></a>Azure Service Fabric でのディザスター リカバリー
高可用性を実現するうえで欠かせないのは、サービスがあらゆる種類の障害を切り抜けられるようにすることです。 これは、計画外の障害や、制御できない障害に関しては特に重要です。 この記事では、正しくモデル化および管理されていない場合に、災害につながる可能性がある一般的な障害モードをいくつか取り上げて説明します。 さらに、軽減策や、災害が発生した場合に実行するアクションについても解説します。 その目的は、計画的または計画外の障害が発生したときに、ダウンタイムやデータ損失のリスクを軽減または排除することです。

## <a name="avoiding-disaster"></a>災害の回避
Service Fabric の主な目的は、一般的な障害が災害につながらないように、環境とサービスの両方をモデル化できるよう支援することです。 

一般的に、災害/障害のシナリオには 2 つの種類があります。

1. ハードウェアまたはソフトウェアのエラー
2. 操作上のエラー

### <a name="hardware-and-software-faults"></a>ハードウェアおよびソフトウェアのエラー
ハードウェアとソフトウェアのエラーは予測できません。 障害を最も簡単に切り抜けるには、ハードウェアまたはソフトウェアのエラーの境界で、より多くのサービス コピーを実行します。 たとえば、サービスが 1 つの特定のマシンでのみ実行されている場合、そのマシンで障害が発生するということは、サービスで災害が発生するということです。 この災害は、サービスを確実に複数のマシンで実行することによって、簡単に回避できます。 1 台のマシンの障害によって実行中のサービスが中断しないように、テストを行う必要もあります。 容量計画によって置換インスタンスを他の場所に作成すれば、容量が減っても、残りのサービスが過負荷になりません。 このパターンは、回避しようとしている障害の種類にかかわらず有効です。 たとえば次のようになります。 SAN の障害が心配であれば、複数の SAN で実行します。 サーバー ラックの損失が心配であれば、複数のラックで実行します。 データセンターの損失が心配であれば、複数の Azure リージョンまたはデータセンターでサービスを実行します。 

このタイプのスパン モードで実行しても、同時に発生する一部の障害の影響はまだ受けます。しかし、1 つの障害と、種類によっては複数の障害 (1 つの VM またはネットワーク リンクの障害など) については自動的に処理されます (もはや "災害" ではありません)。 Service Fabric には、クラスターを拡張するメカニズムが多数用意されており、障害が発生したノードとサービスを元に戻します。 また、このような計画外の障害が本当の意味での災害にならないように、Service Fabric では、サービスのインスタンスを多数実行できます。

障害に対応できる規模でのデプロイを実現できないのには理由があるのでしょう。 たとえば、ハードウェア リソースのコストが、障害が発生する可能性を考えたときに、惜しまずに支払える金額を超えているのかもしれません。 分散アプリケーションを扱う場合は、地理的に離れた場所における追加の通信ホップまたは状態レプリケーション コストにより、許容できない待機時間が発生することがあります。 この線引きはアプリケーションごとに異なります。 特にソフトウェア エラーについては、スケールしようとしているサービスでエラーが発生している可能性があります。 この場合、コピーを増やしても災害を防ぐことはできません。障害の状態が、すべてのインスタンス間で相互に関連付けられているためです。

### <a name="operational-faults"></a>操作上のエラー
サービスが世界規模で分散され、あらゆる冗長性が実現されていても、災害を引き起こすイベントは発生します。 たとえば、ユーザーは誤ってサービスの DNS 名を再構成したり、完全に削除したりするものです。 ステートフルな Service Fabric サービスがあり、誰かがそのサービスを誤って削除したとします。 軽減策がなければ、サービスとそのサービスの状態はすべて失われます。 こうした種類の操作上の災害 ("不測") には、通常の計画外の障害とは異なる復旧対策と手順が必要です。 

このような操作上のエラーを回避する最善の方法を次に示します
1. 環境への作業のためのアクセスを制限する
2. 危険な操作を厳密に監査する
3. 自動化を実施し、手動または帯域外の変更を防止するほか、実際の環境に対する特定の変更を適用前に検証する
4. 破壊的な操作が "ソフト" であることを確認する。 ソフト操作はすぐには有効になりません。一定の時間内であれば操作を元に戻すことができます

Service Fabric には、クラスター操作に対する[ロールベース](service-fabric-cluster-security-roles.md)のアクセス制御など、操作上のエラーを回避するためのメカニズムがいくつか用意されています。 ただし、このような操作上のエラーのほとんどでは、組織的な取り組みと他のシステムが必要です。 Service Fabric には、操作上のエラーを切り抜けるためのメカニズムがいくつか用意されています。中でもよく知られているのは、ステートフル サービスのバックアップと復元です。

## <a name="managing-failures"></a>障害の管理
Service Fabric では、障害を常に自動管理することを目標としています。 ただし、一部の障害については、処理のための追加コードがサービスに必要です。 また、安全性とビジネス継続性の理由により、自動的に対処するべき "_ではない_" 種類の障害もあります。 

### <a name="handling-single-failures"></a>1 つの障害への対処
1 台のマシンで障害が発生する理由はさまざまです。 電源、ネットワーク ハードウェアの障害など、ハードウェアが原因である場合があります。 また、ソフトウェアが原因であることもあります。 これには実際のオペレーティング システムとサービス自体の障害が含まれます。 Service Fabric では、このような障害、たとえば、ネットワークの問題によりマシンが他のマシンから切り離されている、といった状況が自動的に検出されます。

サービスの種類に関係なく、実行されているインスタンスが 1 つだと、そのコードの 1 つのコピーが何らかの理由で失敗した場合に、そのサービスでダウンタイムが発生します。 

すべての障害に対して最も簡単に対応するには、ご自身のサービスを、既定で、複数のノードで実行するようにします。 ステートレス サービスの場合、これを行うには、`InstanceCount` を 1 よりも大きな値に設定します。 ステートフル サービスの場合、推奨最小値は必ず `TargetReplicaSetSize` と `MinReplicaSetSize` が 3 以上です。 サービス コードのコピーを複数実行すると、サービスによって、すべての障害が確実に自動処理されます。 

### <a name="handling-coordinated-failures"></a>組織的障害への対処
クラスター内での組織的障害の原因は、計画的または計画外インフラストラクチャ障害と変更、または計画的ソフトウェア変更のいずれかです。 Service Fabric は、組織的障害が発生しているインフラストラクチャ ゾーンを、障害ドメインとしてモデル化します。 組織的ソフトウェア変更が発生する領域は、アップグレード ドメインとしてモデル化されます。 障害ドメインおよびアップグレード ドメインの詳細については、[こちらのドキュメント](service-fabric-cluster-resource-manager-cluster-description.md)を参照してください。このドキュメントでは、クラスター トポロジと定義について説明しています。

既定では、Service Fabric は、障害ドメインとアップグレード ドメインを考慮して、サービスを実行する場所を計画します。 また、Service Fabric では、既定で複数の障害ドメインとアップグレード ドメインにわたってサービスを実行しようとするため、計画的または計画外変更が発生しても、サービスは使用可能な状態のままです。 

たとえば、電源の障害により、マシン ラックで同時に障害が発生したとします。 サービスの複数のコピーが実行されているため、障害ドメインでの多数のマシンの喪失は、特定のサービスに対する単一障害の別の一例に過ぎません。 障害ドメインの管理が、サービスの高可用性の確保に欠かせないのはこのためです。 Azure で Service Fabric を実行している場合、障害ドメインは自動的に管理されます。 しかし、他の環境では、そうではない可能性があります。 オンプレミスで独自のクラスターを作成する場合は、障害ドメインのレイアウトを必ず正しく計画し、マップしてください。

アップグレード ドメインは、ソフトウェア アップグレードを同時に実行する領域をモデル化するときに役に立ちます。 このため、アップグレード ドメインは、多くの場合、計画的アップグレード中にソフトウェアが停止される境界も定義します。 Service Fabric とサービスの両方のアップグレードが同じモデルに従います。 ローリング アップグレード、アップグレード ドメイン、および予期しない変更による影響をクラスターとサービスが受けないようにするうえで役立つ Service Fabric 正常性モデルの詳細については、次のドキュメントを参照してください。

 - [アプリケーションのアップグレード](service-fabric-application-upgrade.md)
 - [アプリケーション アップグレードのチュートリアル](service-fabric-application-upgrade-tutorial.md)
 - [Service Fabric 正常性モデル](service-fabric-health-introduction.md)

[Service Fabric Explorer](service-fabric-visualizing-your-cluster.md) で提供されるクラスター マップを使用して、クラスターのレイアウトを視覚化できます。

<center>
![Service Fabric Explorer での障害ドメインに分散されたノードの表示][sfx-cluster-map]
</center>

> [!NOTE]
> 障害領域のモデル化、ローリング アップグレード、サービス コードと状態の多くのインスタンスの実行、障害ドメインとアップグレード ドメインでサービスを確実に実行するための配置ルール、および組み込みの正常性の監視は、通常の操作上の問題や障害が災害につながるのを未然に防ぐために、Service Fabric に用意されている機能の**一部**にすぎません。 
>

### <a name="handling-simultaneous-hardware-or-software-failures"></a>ハードウェアまたはソフトウェアの同時障害への対処
ここまでは 1 つの障害について説明しました。 おわかりのように、障害ドメインとアップグレード ドメインで実行されているコード (および状態) のコピーを複数保持するだけで、ステートレス サービスとステートフル サービスの両方を簡単に処理できます。 複数の障害がランダムに同時発生することがあります。 こうした障害は、実際の災害につながる可能性が高くなります。


### <a name="random-failures-leading-to-service-failures"></a>サービス障害につながるランダムに発生する障害
たとえば、サービスの `InstanceCount` が 5 で、このインスタンスが実行されているすべてのノードで同時に障害が発生したとします。 Service Fabric は、自動的に他のノードで置換インスタンスを作成して対応します。 この Service Fabric は、サービスのインスタンス数が望ましい数に戻るまで、置換インスタンスを作成し続けます。 また、`InstanceCount` が-1 に設定されているステートレス サービスがあるとします。これは、クラスター内のすべてのノードで、サービスが実行されていることを意味します。 こうしたインスタンスのいくつかで障害が発生したとします。 この場合、Service Fabric は、サービスが望ましい状態ではないことを認識すると、インスタンスが不足しているノードで、インスタンスを作成しようとします。 

ステートフル サービスについては、この状況は、サービスが永続化状態かどうかによって異なります。 また、サービスのレプリカ数と障害の数によっても異なります。 ステートフル サービスについて災害が発生したかどうかを判断し、それを管理するプロセスは、3 つの段階に従って実行されます。

1. クォーラムの損失があるかどうかを確認する
 - ステートフル サービスのレプリカの大部分が同時にダウンしているときはいつでも、クォーラムの損失が発生しています (プライマリを含む)。
2. クォーラムの損失が永続的かどうかを確認する
 - ほとんどの場合、障害は一時的なものです。 プロセス、ノード、VM が再起動され、ネットワーク パーティションは修復します。 ただし、障害が永続的である場合もあります。 
    - 永続化状態でないサービスの場合、クォーラムまたはレプリカで障害が発生すると、"_直ちに_" 永続的なクォーラム損失が発生します。 Service Fabric は、非永続的なステートフル サービスでクォーラムの損失を検出するとすぐに、(潜在的な) データ損失を宣言して、手順 3. に進みます。 データ損失に進むことは理にかなっています。Service Fabric は、レプリカが戻るのを待っても意味がないことを認識しているためです。また、復旧したとしても、空だからです。
    - 永続的なステートフル サービスの場合、クォーラムまたはレプリカで障害が発生すると、Service Fabric は、レプリカが戻ってクォーラムを復元するのを待ち始めます。 これにより、影響を受けるサービス パーティション ("レプリカ セット") に対するすべての "_書き込み_" でサービス停止が発生します。 ただし、一貫性の保証は少なくなりますが、読み取りはまだ可能です。 続行することは (潜在的な) データ損失イベントとなり、その他のリスクが伴うため、既定では、Service Fabric はクォーラムが復元されるのを無制限に待ち続けます。 `QuorumLossWaitDuration` の既定値は上書きできますが、お勧めしません。 代わりに、この時点で、停止しているレプリカを復元することに全力を尽くしてください。 それには、停止したノードをバックアップし、ローカル継続状態を格納したドライブを確実に再マウントできなければなりません。 クォーラム損失の原因がプロセス障害である場合、Service Fabric は自動的にプロセスを再作成し、その内部でレプリカを再起動しようとします。 これが失敗すると、Service Fabric は正常性エラーを報告します。 解決できた場合、通常、レプリカは戻ります。 ただし、場合によっては、戻らないこともあります。 たとえば、すべてのドライブで障害が発生した場合、または何らかの理由でマシンが物理的に壊れている場合です。 このような場合は、永続的なクォーラム損失イベントが発生します。 停止したレプリカが戻るのを待っている Service Fabric に対して、待つのをやめるように指示するために、クラスター管理者は、どのサービスのどのパーティションが影響を受ているかを判断し、`Repair-ServiceFabricPartition -PartitionId` または ` System.Fabric.FabricClient.ClusterManagementClient.RecoverPartitionAsync(Guid partitionId)` API を呼び出す必要があります。  この API により、クォーラム損失から潜在的なデータ損失に移行するために、パーティションの ID を指定できます。

> [!NOTE]
> 対象の方法以外で特定のパーティションに対してこの API を使用するのは、"_決して_" 安全ではありません。 
>

3. 実際にデータ損失があったかどうかを確認し、バックアップから復元する
  - Service Fabric が `OnDataLossAsync` メソッドを呼び出す場合、その理由は必ずデータ損失の "_疑いがある_" ためです。 Service Fabric により、この呼び出しは確実に "_最適_" な残りのレプリカに配信されます。 これは、最も進捗しているレプリカです。 データ損失の "_疑いがある_" があるという場合、その理由は、残りのレプリカの実際の状態が、プライマリが停止したときのプライマリの状態とまったく同じである可能性があるためです。 しかし、比較対象となる状態がなければ、Service Fabric やオペレーターが適切な方法でそれを確信することはできません。 この時点で、Service Fabric は、他のレプリカが戻らないこともわかっています。 これは、クォーラム損失が解決されるのを待つことをやめたとき行われた決定です。 サービスに対する最善なアクションは、通常、アクションを凍結し、特定の管理介入を待つことです。 では、`OnDataLossAsync` メソッドの一般的な実装では何を行うのでしょう。
  - 最初に、`OnDataLossAsync` がトリガーされたことをログに記録し、必要な管理アラートを起動します。
   - 通常、この時点で、一時停止し、さらなる決定と、手動アクションが実行されるのを待ちます。 これは、バックアップを使用できる場合でも、準備が必要な可能性があるためです。 たとえば、2 つの異なるサービスで情報を調整する場合、復元が発生したときに、その 2 つのサービスに関連する情報の一貫性を確保するために、こうしたバックアップの変更が必要になることがあります。 
  - 多くの場合、サービスの他のテレメトリや消費データも存在します。 このメタデータは、他のサービスまたはログに含まれている可能性があります。 この情報を使用して、バックアップに存在しない、またはこの特定のレプリカにレプリケートされなかった呼び出しが、プライマリで受信および処理されたかどうかを判断します。 復元を実現するには、これを再生するか、バックアップに追加しなければならないことがあります。  
   - 残りのレプリカの状態を、バックアップに含まれるものを比較できます。 Service Fabric の信頼できるコレクションを使用すると、このためのツールやプロセスを入手できます。詳細については、[こちらの記事](service-fabric-reliable-services-backup-restore.md)を参照してください。 その目的は、レプリカ内の状態が十分かどうか、また、バックアップで何が不足しているかを確認することです。
  - 比較の後、必要に応じて復元が行われ、状態が変更されると、サービス コードは true を返します。 レプリカが使用可能な最善の状態のコピーであると判断された場合、変更は行われず、false を返します。 True は、"_他_" の残りのレプリカが、このレプリカと整合性がとれていない可能性があることを示します。 残りのレプリカは削除され、このレプリカから再作成されます。 False は、状態の変更は行われていないため、他のレプリカをそのまま保持できることを意味します。 

サービス作成者が、サービスを運用環境にデプロイする前に、潜在的なデータ損失および障害シナリオを実施することが非常に重要です。 データ損失の可能性を防ぐために、地理冗長ストアへのステートフル サービスの[状態のバックアップ](service-fabric-reliable-services-backup-restore.md)を定期的に行うことも重要です。 また、それを復元する機能を確保する必要もあります。 さまざまなサービスのバックアップがそれぞれ異なるタイミングで行われるため、復元後、こうしたサービスのビューが相互に一貫性があることを確認する必要があります。 たとえば、あるサービスが数値を生成して格納し、その数値を他のサービスに送信したとします。送信先のサービスも、受け取った数値を格納します。 復元後、2 番目のサービスに数値があり、最初のサービスにはないことに気が付きました。これはバックアップに、この操作が含まれていなかったためです。

残りのレプリカが不十分で、データ損失シナリオを続行できない場合、テレメトリまたは消費データからサービスの状態を再構築できないときは、最適な目標復旧時点 (RPO) はバックアップの頻度によって決まります。 Service Fabric には、バックアップからの復元を必要とする永続的なクォーラムとデータ損失など、さまざまな障害シナリオをテストするツールが多数用意されています。 こうしたシナリオは、Fault Analysis Service によって管理される、Service Fabric の Testability ツールに含まれています。 こうしたツールおよびパターンの詳細については、[こちら](service-fabric-testability-overview.md)を参照してください。 

> [!NOTE]
> システム サービスでもクォーラム損失が発生する可能性があり、その影響は問題のあるサービスに固有です。 たとえば、ネーム サービスでクォーラム損失が発生すると名前の解決に影響があり、フェールオーバー マネージャー サービスの場合は新しいサービスの作成とフェールオーバーがブロックされます。 Service Fabric システム サービスは、状態管理のサービスと同じパターンに従いますが、クォーラム損失から潜在的なデータ損失への移行はお勧めしません。 代わりに、[サポートを利用](service-fabric-support.md)して、個別の状況に合ったソリューションを判断することをお勧めします。  通常は、ダウンしたレプリカが復旧するまで待つことをお勧めします。
>

## <a name="availability-of-the-service-fabric-cluster"></a>Service Fabric クラスターの可用性
一般的には、Service Fabric クラスター自体は高度な分散環境で、単一障害点がありません。 どのノードで障害が発生しても、クラスターの可用性または信頼性で問題が発生することはありません。これは主に Service Fabric システム サービスが、前に説明したものと同じガイドラインに従っているためです。つまり、既定で常に 3 つ以上のレプリカで実行され、こうしたステートレスのシステム サービスはすべてのノードで実行されています。 基になる Service Fabric ネットワークとエラー検出レイヤーは完全に分散されています。 システム サービスは総じてメタデータから再構築できるか、他の場所から状態を再同期する方法を認識しています。 クラスターの可用性が低下する可能性があるのは、これまで説明したようなクォーラム損失状態がシステム サービスで発生した場合です。 このような場合、アップグレードの開始、新しいサービスのデプロイなど、一部の操作をクラスターで実行できないことがありますが、クラスター自体はまだ起動しています。 既に実行中のサービスについては、システム サービスに書き込まなくても継続して動作できるのであれば、こうした状況でも引き続き実行されます。 たとえば、Failover Manager でクォーラム損失が発生しても、すべてのサービスが継続して実行されますが、障害が発生しているサービスについては、Failover Manager の関与が必要であるため、自動的に再起動することはできません。 

### <a name="failures-of-a-datacenter-or-azure-region"></a>データセンターまたはAzure リージョンの障害
まれに、停電やネットワーク切断のために、物理的なデータ センターが一時的に使用できなくなることがあります。 このような場合、そのデータセンターまたは Azure リージョンの Service Fabric クラスターとサービスは使用できなくなります。 ただし、"_データは保存されます_"。 Azure で実行されているクラスターの場合、[Azure ステータス ページ][azure-status-dashboard]で停止時の更新を確認できます。 極めてまれなことですが、データ センターが物理的に一部または全体が破壊された場合、そこでホストされている Service Fabric クラスター、またはその中のサービスが失われる可能性があります。 これには、そのデータセンターやリージョンの外でバックアップされていない状態も含まれます。

1 つのデータセンターやリージョンにおける永続的または持続的な障害を切り抜けるための戦略は 2 つあります。 

1. このような複数のリージョンで Service Fabric クラスターをそれぞれ実行し、こうした環境間でのフェールオーバーとフェールバックのメカニズムをいくつか使用します。 このような複数クラスターのアクティブ/アクティブまたはアクティブ/パッシブ モデルには、追加の管理および操作コードが必要です。 また、あるデータセンターやリージョンで障害が発生したときに、その中のサービスを他のデータセンターやリージョンで使用できるように、サービスのバックアップの調整も必要です。 
2. 複数のデータセンターやリージョンにまたがる 1 つの Service Fabric クラスターを実行します。 これがサポートされる最小構成は 3 つのデータ センターまたはリージョンです。 推奨されるリージョンまたはデータセンターの数は 5 つです。 これには、さらに複雑なクラスター トポロジが必要になります。 ただし、このモデルの利点は、1 つのデータセンターまたはリージョンの障害が、災害から通常の障害に変換される点です。 こうした障害は、1 つのリージョン内のクラスターに対して有効なメカニズムで処理できます。 障害ドメイン、アップグレード ドメイン、および Service Fabric の配置ルールにより、通常の障害が許容されるようにワークロードが分散されます。 この種類のクラスターにおけるサービス操作に役立つポリシーの詳細については、[配置ポリシー](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md)に関するページをご覧ください。

### <a name="random-failures-leading-to-cluster-failures"></a>クラスター障害につながるランダムに発生する障害
Service Fabric にはシード ノードの概念があります。 これは基になるクラスターの可用性を維持するノードです。 特定の種類のネットワーク障害が発生しているときに、他のノードとのリースを確立し、タイブレーカーとして機能することで、クラスターが確実に稼働し続けるうえで役立ちます。 ランダムに発生する障害によりクラスターのシード ノードの大部分が削除され、元に戻らない場合、クラスターは自動的にシャット ダウンします。 Azure では、シード ノードが自動的に管理されます。つまり、シード ノードは、使用可能な障害ドメインとアップグレード ドメインに分散され、いずれか 1 つがクラスターから削除されると、代わりとなる 1 つが作成されます。 

スタンドアロンの Service Fabric クラスターと Azure の両方について、シードを実行するのは "プライマリ ノード タイプ" です。 プライマリ ノード タイプを定義するとき、Service Fabric では、システム サービスごとに最大 9 個のシード ノードと 9 個のレプリカを作成することで、提供されるノード数が自動的に使用されます。 ランダムに発生する障害によって、こうしたシステム サービス レプリカの大部分が同時に削除されると、前に説明したように、システム サービスはクォーラム損失に移行します。 シード ノードの大部分が失われた場合、クラスターは直ちにシャット ダウンします。

## <a name="next-steps"></a>次のステップ
- [Testability フレームワーク](service-fabric-testability-overview.md)
- ディザスター リカバリーと高可用性に関する他のリソースを読みます。 Microsoft は、これらのトピックに関して多数のガイダンスを公開しています。 これらのドキュメントの一部は他の製品で使用するための具体的な方法に関するものですが、 Service Fabric にも適用できる多くの一般的なベスト プラクティスが含まれます。
  - [可用性のチェックリスト](../best-practices-availability-checklist.md)
  - [ディザスター リカバリー訓練の実行](../sql-database/sql-database-disaster-recovery-drills.md)
  - [Azure アプリケーションのディザスター リカバリーと高可用性][dr-ha-guide]
- [Service Fabric のサポート オプション](service-fabric-support.md)について学びます。

<!-- External links -->

[repair-partition-ps]: https://msdn.microsoft.com/library/mt163522.aspx
[azure-status-dashboard]:https://azure.microsoft.com/status/
[azure-regions]: https://azure.microsoft.com/regions/
[dr-ha-guide]: https://msdn.microsoft.com/library/azure/dn251004.aspx


<!-- Images -->

[sfx-cluster-map]: ./media/service-fabric-disaster-recovery/sfx-clustermap.png

