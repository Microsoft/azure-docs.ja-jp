---
title: "Service Fabric クラスター リソース マネージャーの概要 | Microsoft Docs"
description: "Service Fabric クラスター リソース マネージャーについての概要。"
services: service-fabric
documentationcenter: .net
author: masnider
manager: timlt
editor: 
ms.assetid: cfab735b-923d-4246-a2a8-220d4f4e0c64
ms.service: Service-Fabric
ms.devlang: dotnet
ms.topic: article
ms.tgt_pltfrm: NA
ms.workload: NA
ms.date: 01/05/2017
ms.author: masnider
translationtype: Human Translation
ms.sourcegitcommit: dafaf29b6827a6f1c043af3d6bfe62d480d31ad5
ms.openlocfilehash: ec470466f006265af5c4ccfddeeba975e6e648b5
ms.lasthandoff: 01/07/2017


---
# <a name="introducing-the-service-fabric-cluster-resource-manager"></a>Service Fabric クラスター リソース マネージャーの概要
従来、IT システムまたは一連のサービスの管理では、いくつかの物理または仮想マシンをそれらの特定のサービスまたはシステム専用に使用しました。 多くの主要なサービスは "Web" 層と "データ" 層または "ストレージ" 層に分かれ、普通はそれ以外にキャッシュなどのいくつかの特殊なコンポーネントがあります。 他には要求が出入りするメッセージ層を持つものアプリケーションの種類がありました。 この層は、メッセージングの一部として必要な分析や変換のための処理層に接続されていたものです。 ワークロードの種類にはそれぞれ専用のマシンが使用されていました。データベースには&2; 個の専用マシンが、Web サーバーには数個が使用されました。 特定の種類のワークロードがそのワークロード用のマシンの能力を超えた場合は、そのワークロード用に構成されたマシンの数を増やしていました。 ただし、ほとんどの場合、一部のマシンを大型のマシンに置き換えていました。 簡単です。 マシンで障害が発生した場合、マシンが復元されるまで、アプリケーションのその部分の処理能力が低下します。 まだ (楽しくはないにしても) 十分に簡単です。

ところが、スケール アウトが必要になり、コンテナーやマイクロサービスを追加する場合を考えてみてください。 突然、数十台、数百台、あるいは数千台のマシンがあることに気付きます。 何十種類ものサービス (マシンの容量すべてに相当するリソースを消費するサービスはありません) があり、おそらくこれらのサービスの何百ものインスタンスがあります。 各名前付きインスタンスには高可用性 (HA) のためのインスタンスまたはレプリカが&1; つ以上あります。

いきなり、環境の管理は、1 種類のワークロードに専用の数台のマシンの管理といった単純なものではなくなります。 サーバーは仮想化されており、もはや名前を持ちません (考え方を *ペットから家畜の牛* に変え [ます](http://www.slideshare.net/randybias/architectures-for-open-and-scalable-clouds/20) )。 マシンに関する構成は減り、サービス自体に関する構成が増えています。 専用ハードウェアは過去のものであり、サービス自体が複数の細分化されたコモディティ ハードウェアにまで及ぶ小規模な分散システムになっています。

このように従来の単一の階層化されたアプリをコモディティ ハードウェアで実行している複数の異なるサービスに分割した結果として、はるかに多くの組み合わせに対応する必要があります。 どのハードウェアまたは何台のハードウェアで実行できるワークロードの種類をだれが決定しますか。 どのワークロードが同じハードウェアで適切に動作し、競合しているでしょうか。 マシンがダウンしても、 何が実行され続けているのでしょうか。 確実にワークロードが再実行する責任はだれにありますか。 (仮想) マシンが回復するまで待ちますか、またはワークロードは自動的に他のマシンにフェールオーバーし、実行し続けていますか。 ユーザーの介入は必要ですか。 この環境でのアップグレードについてはどうですか。

開発者およびオペレーターとして、この複雑さを管理するには何らかの手助けが必要です。 ただし、むやみに人を雇って複雑さを覆い隠そうとすることが正しい答えではないことは何となくわかっています。

どうすればよいでしょうか。

## <a name="introducing-orchestrators"></a>オーケストレーターの導入
"オーケストレーター" とは、管理者がこの種の環境を管理するのを支援するソフトウェアの一般的な用語です。 オーケストレーターは、"このサービスの&5; つのコピーを環境で実行したい" といった要求を受け取るコンポーネントです。 何が起きようとも、環境を望ましい状態にしようとします。

オーケストレーター (人ではありません) は、何らかの予期しない理由によってマシンで障害が発生したりワークロードが中断したりすると活動を開始します。 ほとんどのオーケストレータ―は、ただ障害に対応するだけではありません。 それ以外にも、新しいデプロイの管理、アップグレードの処理、リソース消費の処理などを行います。 オーケストレータ―はすべて、基本的には環境内の構成を何らかの望ましい状態に維持することに関係しています。 管理者としては、オーケストレーターに希望を伝えて重労働を任せることができればいいと思うでしょう。 Mesos 上の Chronos または Marathon、Fleet、Docker データセンター/Docker Swarm、Kubernetes、Service Fabric はすべて、オーケストレーターの例であるか、オーケストレーターが組み込まれています。 異なる種類の環境と条件で実際のデプロイを管理する複雑さは拡大および変化しているので、常に新しいオーケストレーターが作成されています。

## <a name="orchestration-as-a-service"></a>サービスとしてのオーケストレーション
Service Fabric クラスターでのオーケストレーターのジョブは、主にクラスター リソース マネージャーによって行われます。 Service Fabric クラスター リソース マネージャーは Service Fabric 内のシステム サービスの&1; つであり、各クラスターで自動的に起動されます。 一般に、クラスター リソース マネージャーのジョブは&3; つの部分に分かれます。

1. ルールの強制
2. 環境の最適化
3. その他のプロセスの支援

クラスター リソース マネージャーの機能については、次の Microsoft Virtual Academy のビデオをご覧ください。<center><a target="_blank" href="https://mva.microsoft.com/en-US/training-courses/building-microservices-applications-on-azure-service-fabric-16747?l=d4tka66yC_5706218965">
<img src="./media/service-fabric-cluster-resource-manager-introduction/ConceptsAndDemoVid.png" WIDTH="360" HEIGHT="244">
</a></center>

### <a name="what-it-isnt"></a>説明
従来の N 層 Web アプリには、常に "ロード バランサー" の概念が存在しました。 通常は、ネットワーク スタック内での位置によりネットワーク ロード バランサー (NLB) またはアプリケーション ロード バランサー (ALB) と呼ばれていました。 ロード バランサーには、F5 の BigIP のようなハードウェア ベースのものと、Microsoft の NLB のようなソフトウェア ベースのものがあります。 他の環境では、このロールに HAProxy または nginx のようなものがありました。 これらのアーキテクチャでの負荷分散の仕事は、すべての異なるステートレス ワークロードが、(ほぼ) 同じ量の作業を受け取るようにすることです。 負荷分散の方法にはさまざまなものがありました。 一部のロード バランサーは、異なるサーバーにそれぞれ異なる呼び出しを送信していました。 その他のロード バランサーは、セッションの固定や持続性を提供するものでした。 より高度なロード バランサーは、予想されるコストと現状のマシンの負荷に基づいて、実際の推定またはレポートを使用して呼び出しをルーティングします。

ネットワーク ロード バランサーやメッセージのルーターは、Web/ワーカー層をほぼバランスの取れた状態で維持しようとしました。 データ層のバランスをとる方法はそれとは異なり、データ ストレージ メカニズムに依存し、通常はデータ シャーディング、キャッシュ、管理されたビュー、ストアド プロシージャ、およびその他のストア固有のメカニズムが中心でした。

これらの方法の中には興味深いものもありますが、Service Fabric クラスター リソース マネージャーはネットワーク ロード バランサーやキャッシュとはまったく異なるものです。 ネットワーク ロード バランサーは、サービスを実行している場所にトラフィックを移動することによって、フロントエンドのバランスが取れた状態にします。 Service Fabric クラスター リソース マネージャーは、それとは異なる方法を使用します。 基本的に、Service Fabric は*サービス*を最も理にかなった場所に移動し、トラフィックや負荷が追随するようにします。 たとえば、割り当てられているサービスがあまりやることがないために、現在コールド状態になっているノードなどに移動します。 ノードは、存在していたサービスが削除されたか別の場所に移動されたために、コールド状態になっている可能性があります。 クラスター リソース マネージャーが、マシンからサービスを移動する場合もあります。 これは、マシンがアップグレードされようとしているか、実行されているサービスによる使用量の急増により過負荷状態になっているという状況が考えられます。

クラスター リソース マネージャーはサービスを移動させる役割を担う (ネットワーク トラフィックをサービスが既に実行している場所に提供しない) ため、ネットワーク ロード バランサーにあるものとは違った機能セットを持っています。 さらに詳しく見ると、クラスター内のハードウェア リソースが効率的に活用されるようにするため、根本的に異なる方法を採用していることが分かります。

## <a name="next-steps"></a>次のステップ
* クラスター リソース マネージャー内のアーキテクチャと情報フローの詳細については、[この記事](service-fabric-cluster-resource-manager-architecture.md)を確認してください。
* クラスター リソース マネージャーには、クラスターを記述するためのさまざまなオプションがあります。 オプションの詳細については、[Service Fabric クラスターの記述](service-fabric-cluster-resource-manager-cluster-description.md)に関するこの記事を参照してください。
* サービスの構成に利用できるその他のオプションの詳細については、他に利用可能なクラスター リソース マネージャーの構成に関するトピック ([サービスの構成の詳細](service-fabric-cluster-resource-manager-configure-services.md)) を確認してください。
* メトリックは、Service Fabric クラスター リソース マネージャーが管理するクラスターの利用量と容量を表します。 メトリックの詳細とその構成方法については、 [この記事](service-fabric-cluster-resource-manager-metrics.md)
* クラスター リソース マネージャーは Service Fabric の管理機能と連動します。 その統合の詳細については、 [この記事](service-fabric-cluster-resource-manager-management-integration.md)
* クラスター リソース マネージャーでクラスターの負荷を管理し、分散するしくみについては、 [負荷分散](service-fabric-cluster-resource-manager-balancing.md)

