---
title: メディア グラフの概念 - Azure
description: メディア グラフを使用すると、メディアのキャプチャ元、処理方法、および結果の配信先を定義できます。 この記事では、メディア グラフの概念の詳細について説明します。
ms.topic: conceptual
ms.date: 05/01/2020
ms.openlocfilehash: 8c6775da6804b5079c89cae73d4621dd8067e90a
ms.sourcegitcommit: c5021f2095e25750eb34fd0b866adf5d81d56c3a
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 08/25/2020
ms.locfileid: "88798841"
---
# <a name="media-graph"></a>メディア グラフ

## <a name="suggested-pre-reading"></a>推奨される事前読み取り

* [IoT Edge の Live Video Analytics (プレビュー)](overview.md)
* [IoT Edge の Live Video Analytics の用語](terminology.md)

## <a name="overview"></a>概要

メディア グラフを使用すると、メディアのキャプチャ元、処理方法、および結果の配信先を定義できます。 これを行うには、必要な方法でコンポーネントまたはノードを接続します。 メディア グラフを図で表わすと、次の図のようになります。  

![メディア グラフのグラフィック表示](./media/media-graph/overview.png)

IoT Edge の Live Video Analytics では、さまざまな種類のソース、プロセッサ、およびシンクがサポートされています。

* **ソース ノード**は、メディア グラフへのメディアのキャプチャを有効にします。 このコンテキストのメディアは、概念的には、オーディオ ストリーム、ビデオ ストリーム、データ ストリーム、またはオーディオ、ビデオ、データを 1 つのストリームに結合したストリームを指します。
* **プロセッサ ノード**は、メディア グラフ内のメディアの処理を有効にします。
* **シンク ノード**は、メディア グラフの外部にあるサービスとアプリに処理結果を配信できます。

## <a name="media-graph-topologies-and-instances"></a>メディア グラフのトポロジとインスタンス 

IoT Edge の Live Video Analytics では、"グラフ トポロジ" と "グラフ インスタンス" の 2 つの概念によってメディア グラフを管理できます。 グラフ トポロジを使用すると、値のプレースホルダーとしてパラメーターを使用して、グラフのブループリントを定義できます。 トポロジは、メディア グラフでどのノードを使用するか、およびそのノードがメディア グラフでどのように接続されるかを定義します。 たとえば、カメラからフィードを記録する場合は、ビデオを受信するソース ノードとビデオを書き込むシンク ノードを含むグラフが必要になります。

トポロジ内のパラメーターの値は、トポロジを参照するグラフ インスタンスを作成するときに指定します。 これにより、同じトポロジを参照しつつ、トポロジで指定されているパラメーターの値が異なる複数のインスタンスを作成できます。 上記の例では、パラメーターを使用して、カメラの IP アドレスと、録画されたビデオの名前を表すこともできます。 そのトポロジを使用して多数のグラフ インスタンスを作成できます。たとえば、それぞれに特定の IP アドレスと特定の名前が付いている、建物内のカメラごとに 1 つのインスタンスを作成できます。

## <a name="media-graph-states"></a>メディア グラフの状態  

メディア グラフは、次のいずれかの状態になります。

* 非アクティブ –メディア グラフが構成済みで、アクティブではない状態を表します。
* アクティブ化中 – メディア グラフがインスタンス化されている (つまり、非アクティブとアクティブの間の遷移状態) ときの状態です。
* アクティブ – メディア グラフがアクティブになっているときの状態です。 

    > [!NOTE]
    >  メディア グラフは、データが流れていない間もアクティブにすることができます (たとえば、入力ビデオ ソースがオフラインになった場合など)。
* 非アクティブ化中 – メディア グラフがアクティブから非アクティブに遷移しているときの状態です。

次の図は、メディア グラフのステート マシンを示しています。

![メディア グラフのステート マシン](./media/media-graph/media-graph-state-machine.png)

## <a name="sources-processors-and-sinks"></a>ソース、プロセッサ、およびシンク  

IoT Edge の Live Video Analytics では、メディア グラフ内の次の種類のノードがサポートされています。

### <a name="sources"></a>変換元 

#### <a name="rtsp-source"></a>RTSP ソース 

RTSP ソース ノードを使用すると、[RTSP] (https://tools.ietf.org/html/rfc2326 サーバー) からメディアを取り込むことができます。 監視と IP ベースのカメラは、RTSP (リアルタイム ストリーミング プロトコル) と呼ばれるプロトコルでデータを送信します。これは、携帯電話やビデオ カメラなどの他の種類のデバイスとは異なります。 このプロトコルは、サーバー (カメラ) とクライアントの間のメディア セッションを確立して制御するために使用されます。 メディア グラフの RTSP ソース ノードはクライアントとして機能し、RTSP サーバーとのセッションを確立できます。 ほとんどの [IP カメラ](https://en.wikipedia.org/wiki/IP_camera)などの多くのデバイスには、組み込みの RTSP サーバーがあります。 [ONVIF](https://www.onvif.org/) は、[プロファイル G、S & T](https://www.onvif.org/wp-content/uploads/2019/12/ONVIF_Profile_Feature_overview_v2-3.pdf) 準拠デバイスの定義で RTSP をサポートするように指示します。 RTSP ソース ノードでは、認証された接続を有効にするための資格情報と共に RTSP URL を指定する必要があります。

#### <a name="iot-hub-message-source"></a>IoT Hub メッセージのソース 

他の [IoT Edge モジュール](../../iot-edge/iot-edge-glossary.md#iot-edge-module)と同様に、IoT Edge モジュールの Live Video Analytics では、[IoT Edge ハブ](../../iot-edge/iot-edge-glossary.md#iot-edge-hub)を介してメッセージを受信できます。 これらのメッセージは、他のモジュール、またはエッジ デバイスで実行されているアプリ、またはクラウドから送信できます。 このようなメッセージは、モジュールの[名前付きの入力](../../iot-edge/module-composition.md#sink)に配信 (ルーティング) されます。 IoT Hub メッセージのソース ノードを使用すると、このようなメッセージをメディア グラフに配信できます。 これらのメッセージまたは信号は、通常、信号ゲートをアクティブ化するために、メディア グラフの内部で使用できます (後述する[シグナル ゲート](#signal-gate-processor)を参照してください)。 

たとえば、ドアが開かれたときにメッセージを生成する IoT Edge モジュールを作成できます。 そのモジュールからのメッセージを IoT Edge hub にルーティングし、このハブから、メディア グラフの IoT hub メッセージ ソースにルーティングできます。 メディア グラフ内では、IoT hub のメッセージ ソースは、イベントをシグナル ゲート プロセッサに渡すことができます。これにより、RTSP ソースからファイルへのビデオの記録が有効になります。 

### <a name="processors"></a>[プロセッサ]  

#### <a name="motion-detection-processor"></a>モーション検出プロセッサ 

モーション検出プロセッサ ノードを使用すると、ライブ ビデオのモーションを検出できます。 受信したビデオ フレームを調べ、ビデオに動きがあるかどうかを判断します。 モーションが検出されると、そのビデオ フレームをダウンストリーム コンポーネントに渡し、イベントを出力します。 モーション検出プロセッサ ノードを (他のノードと組み合わせて) 使用すると、モーションが検出されたときに受信ビデオの記録をトリガーできます。

#### <a name="frame-rate-filter-processor"></a>フレーム レート フィルター プロセッサ  

フレーム レート フィルター プロセッサ ノードを使用すると、受信したビデオ ストリームのフレームを指定したレートでサンプリングできます。 これにより、さらに処理するためにダウンストリーム コンポーネント (HTTP 拡張プロセッサ ノードなど) に送信されるフレームの数を減らすことができます。

#### <a name="http-extension-processor"></a>HTTP 拡張プロセッサ

HTTP 拡張プロセッサ ノードを使用すると、独自の IoT Edge モジュールをメディア グラフに接続できます。 このノードは、デコードされたビデオ フレームを入力として受け取り、そのようなフレームをモジュールによって公開される HTTP REST エンドポイントにリレーします。 このノードは、必要に応じて、REST エンドポイントで認証することができます。 また、ノードには、ビデオ フレームを REST エンドポイントにリレーする前に、スケールおよびエンコードするための組み込みのイメージ フォーマッタがあります。 スケーラーには、画像の縦横比を維持、埋め込み、または拡張するオプションがあります。 イメージ エンコーダーでは、JPEG、PNG、BMP 形式がサポートされています。

#### <a name="grpc-extension-processor"></a>gRPC 拡張プロセッサ

gRPC 拡張プロセッサ ノードは、デコードされたビデオ フレームを入力として受け取り、そのようなフレームをモジュールによって公開される [gRPC](terminology.md#grpc) エンドポイントにリレーします。 また、ノードには、ビデオ フレームを gRPC エンドポイントにリレーする前に、スケールおよびエンコードするための組み込みのイメージ フォーマッタがあります。 スケーラーには、画像の縦横比を維持、埋め込み、または拡張するオプションがあります。 イメージ エンコーダーでは、jpeg、png、bmp 形式がサポートされています。

#### <a name="signal-gate-processor"></a>シグナル ゲート プロセッサ  

シグナル ゲート プロセッサ ノードを使用すると、あるノードから別のノードにメディアを条件付きで転送できます。 また、メディアとイベントの同期を可能にするバッファーとしても機能します。 一般的なユース ケースでは、RTSP ソース ノードとアセット シンク ノードの間にシグナル ゲート プロセッサ ノードを挿入し、モーション検出プロセッサ ノードの出力を使用してゲートをトリガーします。 このようなメディア グラフでは、モーションが検出された場合にのみビデオが録画されます。

### <a name="sinks"></a>シンク  

#### <a name="asset-sink"></a>アセット シンク  

アセット シンク ノードを使用すると、メディア (ビデオやオーディオ) データを Azure Media Services アセットに書き込むことができます。 1 つのメディア グラフに存在できるアセット シンク ノードは 1 つだけです。 アセットの詳細と、メディアの記録と再生における役割については、[アセット](terminology.md#asset)に関するセクションを参照してください。 このノードのプロパティの使用方法の詳細については、[継続的なビデオ記録](continuous-video-recording-concept.md)に関する記事も参照してください。

#### <a name="file-sink"></a>ファイル シンク  

ファイル シンク ノードを使用すると、メディア (ビデオやオーディオ) データを IoT Edge デバイスのローカル ファイル システム上の場所に書き込むことができます。 メディア グラフには 1 つのファイル シンク ノードしか存在できません。また、シグナル ゲート プロセッサ ノードのダウンストリームにある必要があります。 これにより、出力ファイルの長さが、シグナル ゲート プロセッサのノード プロパティで指定された値に制限されます。

#### <a name="iot-hub-message-sink"></a>IoT Hub メッセージ シンク  

IoT Hub メッセージ シンク ノードを使用すると IoT Edge ハブにイベントを発行できます。 その後、IoT Edge ハブは、エッジ デバイス上の他のモジュールやアプリ、またはクラウド内の IoT Hub にデータをルーティングすることができます (配置マニフェストで指定されているルートごと)。 IoT Hub メッセージ シンク ノードは、モーション検出プロセッサ ノードなどのアップストリーム プロセッサから、または HTTP 拡張プロセッサ ノードを介して外部の推論サービスからイベントを受け取ることができます。

## <a name="rules-on-the-use-of-nodes"></a>ノードの使用に関する規則

メディア グラフ内でさまざまなノードを使用する上で適用される他の規則については、「[グラフ トポロジに関する制限](quotas-limitations.md#limitations-on-graph-topologies-at-preview)」を参照してください。

## <a name="scenarios"></a>シナリオ

上記で定義したソース、プロセッサ、およびシンクを組み合わせて使用することで、ライブ ビデオの分析に関連するさまざまなシナリオでメディア グラフを作成できます。 シナリオの例を次に示します。

* [継続的なビデオ記録](continuous-video-recording-concept.md)
* [イベントベースのビデオ記録](event-based-video-recording-concept.md)
* [ビデオ記録を行わない Live Video Analytics](analyze-live-video-concept.md)

## <a name="next-steps"></a>次のステップ

ライブ ビデオ フィードでモーション検出を実行する方法については、「[クイック スタート:ご自分のモデルを使用して Live Video Analytics を実行する](use-your-model-quickstart.md)」を参照してください。
