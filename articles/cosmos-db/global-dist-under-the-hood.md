---
title: Azure Cosmos DB のグローバル配信 - 内部のしくみ
description: この記事では、Azure Cosmos DB のグローバル配信に関する技術的な詳細について説明します
author: dharmas-cosmos
ms.service: cosmos-db
ms.topic: conceptual
ms.date: 10/10/2018
ms.author: dharmas
ms.reviewer: sngun
ms.openlocfilehash: e1c84bb28747cf1799b39c70b6df3dc0cb9f8d78
ms.sourcegitcommit: 8330a262abaddaafd4acb04016b68486fba5835b
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 01/04/2019
ms.locfileid: "54038944"
---
# <a name="azure-cosmos-db-global-distribution---under-the-hood"></a>Azure Cosmos DB のグローバル配信 - 内部のしくみ

Azure Cosmos DB は Azure の基本的サービスの 1 つなので、パブリック クラウド、ソブリン クラウド、国防総省 (DoD) クラウド、政府機関クラウドなど世界中の Azure リージョンすべてでデプロイできます。 1 つのデータセンターで、専用のローカル ストレージをそれぞれのマシンで使用して大量のスタンプで Azure Cosmos DB をデプロイおよび管理します。 Azure Cosmos DB は 1 つのデータセンターの多数のクラスターでデプロイされます。各クラスターは、さまざまな世代のハードウェアを実行する可能性があります。 通常、特定のクラスター内のマシンは 10 から 20 の範囲の障害ドメインにまたがります。 次の図は、Cosmos DB グローバル分散システムのトポロジを示したものです。

![システム トポロジ](./media/global-dist-under-the-hood/distributed-system-topology.png)

**Azure Cosmos DB におけるグローバル分散はターンキー方式です。** いつでも数回クリックするか、プログラムを使用して API を 1 回呼び出すだけで、ユーザーは自分の Cosmos データベースに関連付けられている地理的リージョンを追加または削除することができます。 Cosmos データベースは一連の Cosmos コンテナーで構成されます。 Cosmos DB では、コンテナーは分散とスケーラビリティの論理ユニットとしての役割を果たします。 作成するコレクション、テーブル、グラフは、単に Cosmos コンテナーとして (内部的に) 示されます。 それぞれのコンテナーは完全にスキーマが独立していて、それそれがクエリのスコープを持ちます。 Cosmos コンテナー内のデータはインジェスト時に自動的にインデックス作成されます。 自動インデックスにより、ユーザーはスキーマを扱ったりインデックス管理に手間をかけたりすることなくデータのクエリを実行できます。特に、グローバル分散セットアップ時にその点が役立ちます。  

- 特定のリージョンにあるコンテナー内のデータはパーティション キーを使用して分散されます。パーティション キーはユーザーが提供し、基本的な物理パーティションで透過的に管理されます (ローカル分散)。  

- これに加えて、各物理パーティションには地理的リージョンをまたいでレプリケーションを実施しています (グローバル分散)。 

Cosmos DB を使用するアプリが Cosmos コンテナーでスループットをエラスティックにスケーリングするとき (または多くのストレージを使用するとき)、Cosmos DB はすべてのリージョンにおいてパーティション管理処理 (分割、複製、削除など) を透過的に処理します。 このため、Cosmos DB からはスケール、分散、障害とは関係なく常に、任意の数のリージョンにわたってグローバルに分散された、コンテナー内のデータのシステム イメージが 1 つだけ提供されます。  

次の図に示されているように、コンテナー内のデータは 2 つのディメンションに沿って分散されます。  

![物理パーティション](./media/global-dist-under-the-hood/distribution-of-resource-partitions.png)

物理パーティションはレプリカ セットと呼ばれるレプリカのグループによって実装されます。 前の図に示したように、各マシンは固定セットのプロセス内のさまざまな物理パーティションに対応するたくさんのレプリカをホストします。 物理パーティションに対応するレプリカは動的に配置されて、1 つのクラスター内の多数のマシンと 1 つのリージョン内の多数のデータセンター内で負荷を分散します。  

レプリカは、特定の Azure Cosmos DB テナントに一意に属します。 各レプリカは Cosmos DB の[データベース エンジン](https://www.vldb.org/pvldb/vol8/p1668-shukla.pdf) インスタンスをホストします。このインスタンスは、リソースおよび関連するインデックスを管理します。 Cosmos DB データベース エンジンは、Atom-Record-Sequence (ARS) ベースの型システムで動作します。 このエンジンはスキーマの点で独立していて、レコードの構造体とインスタンス値の境界をぼかします。 Cosmos DB ではインジェスト時に自動的に効率的な方法ですべてをインデックス作成することにより、完全なスキーマ独立を実現しています。これにより、ユーザーはスキーマを処理したり、インデックス管理を行ったりすることなくグローバルに分散されたデータをクエリできます。

Cosmos DB データベース エンジンは、いくつかの調整プリミティブ、言語ランタイム、クエリ プロセッサー、およびデータのトランザクション ストレージとインデックス作成を担うストレージ サブシステムとインデックス作成サブシステムなどを実装するいくつかのコンポーネントで構成されます。 耐久性と高可用性を提供するため、このデータベース エンジンは SSD 上にデータとインデックスを保持し、レプリカ セット内のデータベース エンジン インスタンス間でレプリケーションを行います。 テナントの規模が大きいほどスケールの大きなスループットとストレージに対応し、レプリカの規模も大きくなるか、レプリカの頻度が多くなる、あるいはその両方が備わります。 システム内のすべてのコンポーネントは完全に非同期です。スレッドはブロックされることなく、各スレッドは、不要なスレッド切り替えが生じることなく短期間動作します。 レート制限とバック プレッシャが、管理制御からすべての I/O パスに至るまでスタック全体で組み込まれています。 このデータベース エンジンはきめ細かいコンカレンシーを活用するように、および少量のシステム リソースで運用しながら高スループットを実現するように設計されています。

Cosmos DB のグローバル分散は、レプリカ セットとパーティション セットという 2 つの主要な抽象化に依存しています。 レプリカ セットはモジュール式の調整用レゴ ブロックで、パーティション セットは地理的に分散された 1 つ以上の物理パーティションの動的オーバーレイです。 グローバル分散のしくみを理解するには、これら 2 つの主要な抽象化について理解する必要があります。 

## <a name="replica-sets"></a>レプリカセット

物理パーティションは、複数の障害ドメインにまたがっているセルフ マネージド方式で動的に負荷を分散するレプリカ グループ (別名、レプリカ セット) として実現します。 このセットは、レプリケートされたステート マシン プロトコルを集合的に実装し、物理パーティション内のデータの高可用性、耐久性、および整合性を確保します。 レプリカ セットのメンバーシップ N は動的です。障害、管理操作、および再生成/回復のためのレプリカの失敗時点に基づいて NMin から NMax までの範囲で変動します。 メンバーシップが変更すると、レプリケーション プロトコルも読み取りと書き込みのクォーラムのサイズを再構成します。 特定の物理パーティションに割り当てられるスループットを統一感を持って分散するため、2 つのアイデアを採用しています。1 つ目は、リーダーにおける書き込み要求の処理コストは、フォロワーにおける更新に適用されるコストよりも高くなるという点です。 それに対応して、リーダーに割り当てられるシステム リソースはフォロワーよりも多くなっています。 2 番目に、可能な限り、指定の整合性レベルの読み取りクォーラムはフォロワー レプリカによってのみ構成されます。 必要な場合を除き、読み取りのためにリーダーにアクセスしないようにします。 Cosmos DB がサポートしている 5 つの整合性モデルのクォーラム ベースのシステムにおける[負荷とキャパシティ](https://www.cs.utexas.edu/~lorenzo/corsi/cs395t/04S/notes/naor98load.pdf)の関係に関して実施された研究に基づいて数多くのアイデアを採用しています。  

## <a name="partition-sets"></a>パーティション セット

物理パーティションのグループは、それぞれが Cosmos データベース リージョンで構成されているリソース パーティションから成り、構成されているすべてのリージョンでレプリケートされた同じキー セットを管理します。 この高度な調整プリミティブはパーティション セットと呼ばれ、特定のキー セットを管理する物理パーティションの地理的に分散された動的オーバーレイです。 指定された物理パーティション (レプリカ セット) は 1 つのクラスター内のものですが、パーティション セットは、次の図に示すように、複数のクラスター、データ センター、地理的リージョンにまたがることができます。  

![パーティション セット](./media/global-dist-under-the-hood/dynamic-overlay-of-resource-partitions.png)

パーティション セットは、同じキー セットを所有する複数のレプリカ セットで構成されている、地理的に分散している “スーパー レプリカ セット” と見なすことができます。 レプリカ セットと同様に、パーティション セットのメンバーシップも動的で、特定のパーティション セットに新しいパーティションを追加または削除するための暗黙的な物理パーティション管理操作に基づいて変動します (たとえば、コンテナーのスループットをスケールアウトした場合や、Cosmos データベースにリージョンを追加または削除した場合や、エラーが発生した場合)。(パーティション セットの) 各パーティションにそれ自身のレプリカ セット内のパーティション セット メンバーシップを管理させることによって、メンバーシップが完全に分散され、高可用性を実現できます。 パーティション セットを再構成する間に、物理パーティション間のオーバーレイのトポロジも確立されます。 トポロジは整合性レベル、地理的距離、およびソースとターゲットの物理パーティション間で利用できるネットワーク帯域幅に基づいて動的に選択されます。  

このサービスを使用することによって、単一の書き込みリージョンと複数の書き込みリージョンのいずれかで Cosmos データベースを構成できます。このどちらを選択するかに基づいて、パーティション セットで書き込みを行えるよう構成されるのが 1 つのリージョンのみかすべてのリージョンにおいてであるかが決まります。 システムでは 2 つのレベルの入れ子になったコンセンサス プロトコルが導入されています。1 つのレベルは、書き込みを承認する物理パーティションのレプリカ セットのレプリカで動作します。もう 1 つはパーティション セット レベルで動作して、パーティション セット内のコミットされたすべての書き込みが順序どおりに実行されることを保証します。 このマルチレイヤーの入れ子になったコンセンサスは、高可用性に関する当社の厳密な SLA の遂行や、Cosmos DB がお客様に提供する整合性モデルの実装において重要となります。  

## <a name="conflict-resolution"></a>競合の解決

更新の伝達、競合解決、因果関係の追跡に関する Microsoft の設計は、以前の[エピデミック アルゴリズム](https://www.cs.utexas.edu/~lorenzo/corsi/cs395t/04S/notes/naor98load.pdf)と [Bayou](https://zoo.cs.yale.edu/classes/cs422/2013/bib/terry95managing.pdf) システムからヒントを得ています。 Cosmos DB のシステム設計ではカーネルの概念が引き続き採用され、通信に便利な参照フレームが導入されていますが、Cosmos DB システムに適用されるときに大幅な変更が加えられています。 こうした変更が必要となったのは、以前のシステムにおいては、Cosmos DB で必要なリソース管理もスケールも不要で、Cosmos DB がお客様に提供するさまざまな機能 (有界整合性制約など) や厳密で包括的な SLA を提供する必要もなかったためです。  

パーティション セットは複数のリージョンで分散され、Cosmos DB の (マルチマスター) レプリケーション プロトコルを導入して、特定のパーティション セットを構成する物理パーティション間でデータをレプリケートするという点を思い出してください。 (パーティション セットの) それぞれの物理パーティションは書き込みを承諾し、対象リージョンに対してローカルなクライアントに対して通常読み取りを行います。 リージョン内の物理パーティションで承諾された書き込みは耐久性の高い状態でコミットされ、クライアントに対して確認応答する前に物理パーティションで高可用になります。 これらは仮の書き込みで、アンチエントロピ チャネルを使用してパーティション セットの他の物理パーティションに伝達されます。 クライアントは、要求ヘッダーを引き渡すことによって、仮の書き込みまたはコミット済みの書き込みを要求できます。 アンチエントロピ伝達 (伝達頻度も含む) は、パーティション セットのトポロジ、物理パーティション間のリージョンの近接度、構成されている整合性レベルに基づいて動的に行われます。 パーティション セット内では、Cosmos DB は動的に選択されたアービター パーティションが含まれるプライマリ コミット スキーマに従います。 アービターの選択は動的で、オーバーレイのトポロジに基づくパーティション セットの再構成において不可欠な部分です。 コミット済み書き込み (複数行/バッチ更新を含む) は順序どおりに実行されることが保証されます。 

因果関係の追跡とバージョン ベクターにおいて更新の競合を検出して解決するために、エンコードされたベクター クロックを導入しました (レプリカ セットとパーティション セットのそれぞれのレベルのコンセンサスに対応するリージョン ID と論理クロックが含まれます)。 このトポロジとピア選択アルゴリズムは、バージョン ベクターの固定の最小限のストレージと最小限のネットワーク オーバーヘッドを確保するよう設計されています。 このアルゴリズムによって、厳密な収束プロパティが保証されます。  

複数の書き込みリージョンが構成されている Cosmos データベースの場合、システムによって、開発者が選択できる多数の柔軟な自動競合解決ポリシーが提供されています。以下の選択肢が含まれます。 

- 最後の書き込みが有効 (LWW)。既定では、ユーザーはシステム定義のタイムスタンプ プロパティを使用します (時刻同期クロック プロパティに基づきます)。 また Cosmos DB を使用することによって、競合解決に使用する他のカスタムの数値型プロパティを指定できます。  
- アプリケーション定義のカスタム競合解決ポリシー (マージ プロシージャとして表現)。競合のアプリケーション定義のセマンティクス調整用に設計されています。 これらのプロシージャは、データベース トランザクションの支援によって書き込み間の競合が検出されると、サーバー側で呼び出されます。 システムにより、コミットメント プロトコルの一部としてマージ プロシージャの実行が 1 回だけとなることが保証されます。 利用可能ないくつかのサンプルが準備されています。  

## <a name="consistency-models"></a>整合性モデル

Cosmos データベースで単一または複数の書き込みリージョンのどちらを構成した場合であっても、5 つの明確に定義された整合性モデルから選択できます。 複数の書き込みリージョンを可能にする新たに追加されたサポートに関しては、整合性レベルの以下の側面に注目できます。  

これまで同様、有界整合性制約では、すべてのリージョンにおいて、読み取りすべてが最新の書き込みから k プレフィックスまたは t 秒以内に行われることが保証されます。 また、有界整合性制約を使用した読み取りでは、モノトニックになり、一貫性のあるプレフィックスとなることが保証されます。 アンチエントロピ プロトコルはレートが制限された状態で実行され、プレフィックスが累積しないことと、書き込みのバックプレッシャを適用する必要がないことが保証されます。 セッションの整合性の場合も従来どおり、モノトニックな読み取り、モノトニックな書き込み、独自の書き込みの読み取り、読み取り後の書き込み、一貫性のあるプレフィックスが世界規模で保証されます。 強力な一貫性により構成されたデータベースの場合、リージョン全体で同期レプリケーションが行われるため、マルチマスター (短い書き込み待機時間、高い書き込み可用性) の利点が適用されません。

Cosmos DB の 5 つの整合性モデルのセマンティクスについては[こちら](consistency-levels.md)で取り上げられています。また、[こちら](https://github.com/Azure/azure-cosmos-tla)では高水準の TLA+ 仕様を使用して数学的に示されています。

## <a name="next-steps"></a>次の手順

次に、次の記事を使用してグローバル分散を構成する方法について説明します。

* [マルチホームに関するクライアントの構成方法](how-to-manage-database-account.md#configure-clients-for-multi-homing)
* [データベース アカウントのリージョンの追加/削除](how-to-manage-database-account.md#addremove-regions-from-your-database-account)
* [SQL API アカウント用のカスタム競合解決ポリシーを作成する方法](how-to-manage-conflicts.md#create-a-custom-conflict-resolution-policy)
