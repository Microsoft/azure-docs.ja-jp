---
title: Azure Data Lake Storage Gen2 の使用に関するベスト プラクティス | Microsoft Docs
description: データ インジェスト、データのセキュリティ、および Azure Data Lake Storage Gen2 (以前は Azure Data Lake Store と呼ばれていました) の使用に関連するパフォーマンスのベスト プラクティスについて説明します
author: normesta
ms.subservice: data-lake-storage-gen2
ms.service: storage
ms.topic: conceptual
ms.date: 12/06/2018
ms.author: normesta
ms.reviewer: sachins
ms.openlocfilehash: e008bad2043d8cd633f0849aefc62c4ed7a7e89d
ms.sourcegitcommit: d7008edadc9993df960817ad4c5521efa69ffa9f
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/08/2020
ms.locfileid: "86104879"
---
# <a name="best-practices-for-using-azure-data-lake-storage-gen2"></a>Azure Data Lake Storage Gen2 の使用に関するベスト プラクティス

この記事では、Azure Data Lake Storage Gen2 の操作に関するベスト プラクティスと考慮事項について説明します。 この記事では、Data Lake Storage Gen2 のセキュリティ、パフォーマンス、回復性、監視に関連する情報を取り上げます。 Data Lake Storage Gen2 が登場するまで、Azure HDInsight などのサービスで大規模なビッグ データを取り扱うことは大変な作業でした。 ペタバイト クラスのストレージとそのスケールでの最適なパフォーマンスを達成できるように、複数の Blob Storage アカウント間でデータをシャードする必要がありました。 Data Lake Storage Gen2 では、最大 5 TB の個別ファイル サイズがサポートされており、パフォーマンスのハード制限のほとんどが削除されています。 ただし、Data Lake Storage Gen2 で最適なパフォーマンスを得るための考慮事項がまだいくつか残っています。この記事ではそれについて取り上げます。

## <a name="security-considerations"></a>セキュリティに関する考慮事項

Azure Data Lake Storage Gen2 には、Azure Active Directory (Azure AD) のユーザー、グループ、およびサービス プリンシパル用の POSIX アクセス制御が用意されています。 これらのアクセス制御は既存のファイルやディレクトリに設定できます。 アクセス制御は、新しいファイルやディレクトリに自動的に適用できる既定のアクセス許可を作成するためにも使用できます。 Data Lake Storage Gen2 の ACL の詳細については、「[Access control in Azure Data Lake Storage Gen2](storage-data-lake-storage-access-control.md)」(Azure Data Lake Storage Gen2 のアクセス制御) を参照してください。

### <a name="use-security-groups-versus-individual-users"></a>セキュリティ グループの使用と個々のユーザーの違い

Data Lake Storage Gen2 でビッグ データを取り扱うときは、サービス プリンシパルを使用して、Azure HDInsight などのサービスによるデータの操作を許可することがほとんどです。 ただし、個々のユーザーがデータにアクセスする必要がある場合もあります。 いずれの場合でも、個々のユーザーをディレクトリやファイルに割り当てる代わりに、Azure Active Directory の[セキュリティ グループ](../common/storage-auth-aad.md)を使用することを強くお勧めします。

一度セキュリティ グループにアクセス許可が割り当てられると、Data Lake Storage Gen2 を更新することなくグループへのユーザーの追加と削除を行うことができます。 これは、アクセス制御リスト (ACL) あたりのアクセス制御エントリ数の上限を超えないようにするためにも役立ちます。 現在のところ、この数は 32 です (あらゆるファイルとディレクトリに常に関連付けられる、所有ユーザー、所有グループ、マスク、およびその他という 4 つの POSIX スタイルの ACL が含まれます)。 各ディレクトリはアクセス ACL と既定の ACL という 2 種類の ACL を持つことができ、アクセス制御エントリ数の合計は 64 になります。 これらの ACL の詳細については、[Azure Data Lake Storage Gen2 でのアクセス制御](data-lake-storage-access-control.md)に関するページを参照してください。

### <a name="security-for-groups"></a>グループのセキュリティ

お客様またはお客様のユーザーが階層型名前空間を有効にしたストレージ アカウント内のデータにアクセスする必要がある場合は、Azure Active Directory セキュリティ グループを使用することをお勧めします。 まず、コンテナーのルートに **ReadOnlyUsers**、**WriteAccessUsers**、**FullAccessUsers** のいずれかのグループを設定し、主なサブディレクトリには別のグループも設定することをお勧めします。 後でその他のユーザーのグループを追加する可能性があるものの、まだ特定されていない場合は、特定のフォルダーへのアクセス権限が付与されたダミーのセキュリティ グループを作成することをおすすめします。 セキュリティ グループを使用すると、何千ものファイルに新しいアクセス許可を割り当てるときに、処理時間がそれほどかからなくて済みます。

### <a name="security-for-service-principals"></a>サービス プリンシパルのセキュリティ

Azure Active Directory のサービス プリンシパルは、一般的に Azure Databricks などのサービスで、Data Lake Storage Gen2 のデータにアクセスするために使用されます。 多くのお客様には、Data Lake Storage Gen2 コンテナーのルートのフル アクセスが付与された Azure Active Directory のサービス プリンシパルが 1 つあれば十分です。 お客様によっては、1 つのクラスターはデータへのフル アクセス、もう 1 つのクラスターには読み取りアクセスのみなど、複数のクラスターに別個のサービス プリンシパルを要求する場合があります。 

### <a name="enable-the-data-lake-storage-gen2-firewall-with-azure-service-access"></a>Azure のサービス アクセスに対して Data Lake Storage Gen2 のファイアウォールを有効にする

Data Lake Storage Gen2 には、ファイアウォールを有効にして、アクセスを Azure のサービスに限定するオプションが用意されており、外部からの攻撃ベクターを制限するためにお勧めです。 ストレージ アカウントのファイアウォールは、Azure portal の **[ファイアウォール]**  >  **[ファイアウォールを有効にする] を [オン]**  >  **[Azure サービスへのアクセスを許可]** オプションで有効にすることができます。

Azure Databricks からご利用のストレージ アカウントにアクセスするには、Azure Databricks をご利用の仮想ネットワークにデプロイしてから、その仮想ネットワークをご利用のファイアウォールに追加します。 「[Azure Storage ファイアウォールおよび仮想ネットワークを構成する](https://docs.microsoft.com/azure/storage/common/storage-network-security)」を参照してください。

## <a name="resiliency-considerations"></a>回復性に関する考慮事項

Data Lake Storage Gen2 などのクラウド サービスでシステムを構築するときは、可用性の要件と、サービスで中断が発生したときの対応について考慮する必要があります。 ある問題は特定のインスタンスに限定またはリージョン全域にわたる可能性があるため、両方について計画しておくことが重要です。 ワークロードの目標復旧時間と目標復旧ポイントの SLA によっては、高可用性とディザスター リカバリーのために多少は積極的な戦略を選択することをお勧めします。

### <a name="high-availability-and-disaster-recovery"></a>高可用性とディザスター リカバリー

高可用性 (HA) とディザスター リカバリー (DR) は結合して取り扱うこともありますが、それぞれの戦略は特にデータに関してはわずかに異なります。 Data Lake Storage Gen2 は局所的なハードウェア障害に備えて、既に内部的に 3 倍のレプリケーションを処理しています。 さらに、ZRS、GZRS などの他のレプリケーション オプションで HA が改善され、GRS および RA-GRS で DR が改善されます。 HA の計画をビルドするとき、サービスの中断が発生した場合に備えて、ワークロードはローカルまたは新しいリージョンに別途レプリケートしたインスタンスに切り替えることで、できるだけ早く最新のデータにアクセスする必要があります。

DR 戦略では、あるリージョンで壊滅的な障害が万が一に発生した場合に備えて、GRS または RA-GRS レプリケーションを使用して別のリージョンにデータをレプリケートすることも重要です。 エッジ ケースに対応する要件も考慮する必要があります。たとえば、データの破損では、定期的にスナップショットを作成してフォールバックする必要があります。 データの重要度とサイズによっては、リスクの許容範囲に応じて、1 時間、6 時間、24 時間の期間の差分スナップショットを実行することを検討してください。

Data Lake Storage Gen2 のデータの回復性のために、HA/DR の要件を満たす GRS または RA-GRS を介してデータを geo レプリケートすることをお勧めします。 さらに、Data Lake Storage Gen2 を使用するアプリケーションが失敗した試行のトリガーや長さを監視してセカンダリ リージョンに自動的にフェールオーバーするか、少なくとも管理者に通知を送信して手動で介入してもらう方法を考慮してください。 フェールオーバーには、サービスがオンラインに戻ってくるのを待つことと比較して、デメリットが存在します。

### <a name="use-distcp-for-data-movement-between-two-locations"></a>Distcp を使用して 2 つの場所の間でデータを移動する

DistCp (distributed copy の省略形) は Hadoop に付属の Linux のコマンドライン ツールで、2 つの場所の間でデータを分散移動します。 2 つの場所として、Data Lake Storage Gen2、HDFS、または S3 を指定できます。 このツールは Hadoop クラスター (HDInsight など) で MapReduce ジョブを使用してすべてのノードでスケールアウトします。 Distcp は、特別なネットワーク圧縮アプライアンスを使用せずにビッグデータを移動できる、最速の方法と見なされています。 また、Distcp には 2 つの場所間のデルタのみを更新する、自動再試行を処理する、計算の動的な拡大縮小を実行するオプションが用意されています。 この手法は、単一のディレクトリにサイズの大きなファイルが大量にあり、変更があったデータのみを上書きコピーする、Hive/Spark のテーブルなどをレプリケートする場合に非常に効率的です。 これらの理由から、Distcp はビッグ データ ストア間でデータをコピーする最もおすすめのツールです。

コピー ジョブは、Apache Oozie ワークフローで頻度やデータ トリガージョブを使用するほか、Linux の cron トリガーを使用してトリガーできます。 負荷の大きなレプリケーション ジョブでは、コピー ジョブに特化してチューニングおよび拡大できる、別個の HDInsight Hadoop クラスターをスピンアップすることをおすすめします。 これにより、コピー ジョブが重要なジョブを妨害することがなくなります。 十分な間隔を空けた頻度でレプリケーションを実行すると、クラスターが各ジョブ間で分解されることもあります。 セカンダリ リージョンにフェールオーバーされる場合、Data Lake Storage Gen2 のプライマリ アカウントが復旧した後に新しいデータが再度レプリケートされるように、セカンダリ リージョンでもう 1 つのクラスターもスピンアップされていることを確認してください。 Distcp の使用例については、[Distcp を使用して Azure Storage BLOB と Data Lake Storage Gen2 の間でデータをコピーする方法](../blobs/data-lake-storage-use-distcp.md)に関するページを参照してください。

### <a name="use-azure-data-factory-to-schedule-copy-jobs"></a>Azure Data Factory を使用してコピー ジョブのスケジュールを設定する

Azure Data Factory ではコピー アクティビティを使用してコピー ジョブのスケジュールを設定できるほか、コピー ウィザードで頻度を設定することもできます。 Azure Data Factory にはクラウド データ移動単位 (DMU) の制限があり、最終的に大規模なデータ ワークロードのスループット/計算に上限を設定します。 さらに、Azure Data Factory では現在、Data Lake Storage Gen2 アカウント間のデルタの更新は提供しておらず、Hive のテーブルなどのディレクトリをレプリケートするには、完全なコピーが必要になります。 Data Factory のコピーに関する詳細については、[データ ファクトリの記事](../../data-factory/load-azure-data-lake-storage-gen2.md)を参照してください。

## <a name="monitoring-considerations"></a>監視に関する考慮事項

Data Lake Storage Gen2 では、Azure portal 内の Data Lake Storage Gen2 アカウントと、Azure Monitor 内にメトリックが用意されています。 Data Lake Storage Gen2 の可用性は、Azure portal に表示されます。 Data Lake Storage Gen2 アカウントの最新の可用性を取得するには、独自の統合テストを実行して可用性を検証する必要があります。 合計ストレージ使用率、読み取り/書き込み要求数、イングレス/エグレスなどの他のメトリックを監視アプリケーションから利用することができます。また、しきい値 (たとえば、平均待機時間や 1 分あたりのエラー数) を超えたときにアラートをトリガーすることもできます。

## <a name="directory-layout-considerations"></a>ディレクトリのレイアウトに関する考慮事項

データを Data Lake にランディングするときは、セキュリティ、パーティション分割、プロセスが効果的に活用されるように、データの構造を事前に計画することが重要です。 次の推奨事項の多くは、すべてのビッグ データ ワークロードに適用できます。 すべてのワークロードのデータの消費方法に関する要件は異なりますが、以下に IoT およびバッチのシナリオを操作するときの共通のレイアウトをいくつか紹介します。

### <a name="iot-structure"></a>IoT の構造

IoT のワークロードでは、データ ストアにランディングできるデータは、製品、端末、組織、お客様と多岐にわたります。 ダウンストリーム コンシューマーのために、組織のディレクトリのレイアウト、セキュリティ、データの効率的な処理について、事前に計画することが重要です。 考慮する一般的なテンプレートは、次のようなレイアウトになります。

*{Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/*

たとえば、英国の飛行機のエンジンのランディング テレメトリは次のような構造になります。

*UK/Planes/BA1293/Engine1/2017/08/11/12/*

ディレクトリ構造の最後に日付を追加することには、重要な意味があります。 特定のリージョンや主題をユーザー/グループにロック ダウンする場合、POSIX のアクセス許可で簡単に行うことができます。 そうしない場合、特定のセキュリティ グループによる閲覧を英国のデータや特定の飛行機に限定する必要があると、日付構造が前では、毎時のディレクトリ以下にある多数のディレクトリに個別のアクセス許可が必要になります。 さらに、日付構造を前にすると、時間が経過するにつれディレクトリの数が指数関数的に増加します。

### <a name="batch-jobs-structure"></a>バッチ ジョブの構造

大まかにいうと、バッチ処理で一般的に使用される基本的な方法は、"in" ディレクトリにデータをランディングする方法です。 次に、データが処理されると、ダウンストリームのプロセスが消費できるように、新しいデータが "out" ディレクトリに入ります。 このディレクトリ構造は、個々のファイルで処理が必要なプロセスで、大規模なデータセット上で膨大な並列処理が必要とされない可能性があるジョブで見られます。 前述の推奨される IoT の構造と同様に、優れたディレクトリ構造にはリージョンや主題 (例: 組織、製品/製造業者) など、親レベルのディレクトリがあります。 この構造により、組織全体でデータの安全を確保し、ワークロードのデータをより管理しやすくなります。 さらに、プロセスでより優れた組織、フィルター検索、セキュリティ、自動化を実現するために、構造で日付と時間を考慮します。 日付構造の細分性のレベルは、データがアップロードまたは処理される間隔 (毎時、毎日、毎月など) によって決まります。

ファイルのプロセスがデータの破損や予期しない形式により失敗することがあります。 このようなケースでは、 **/bad** フォルダーにファイルを移動してさらに調査すると便利な場合があります。 また、バッチ ジョブはこれらの "*不良*" ファイルのレポート作成や通知を管理し、手動で介入できるようにします。 次のテンプレート構造を考慮してください。

*{Region}/{SubjectMatter(s)}/In/{yyyy}/{mm}/{dd}/{hh}/* \
*{Region}/{SubjectMatter(s)}/Out/{yyyy}/{mm}/{dd}/{hh}/* \
*{Region}/{SubjectMatter(s)}/Bad/{yyyy}/{mm}/{dd}/{hh}/*

たとえば、ある北米のマーケティング企業は、更新されたお客様情報の抽出データをクライアントから毎日受け取ります。 処理される前と後では、次のスニペットのようになります。

*NA/Extracts/ACMEPaperCo/In/2017/08/14/updates_08142017.csv*\
*NA/Extracts/ACMEPaperCo/Out/2017/08/14/processed_updates_08142017.csv*

Hive や従来の SQL データベースなどのデータベースで直接処理される一般的なバッチ データの場合、出力は既に Hive テーブルまたは外部データベースの別のフォルダーに入るように設定されているため、 **/in** フォルダーや **/out** フォルダーは不要です。 たとえば、お客様からの毎日の抽出データはそれぞれのフォルダーにランディングし、Azure Data Factory、Apache Oozie、Apache Airflow などによるオーケストレーションは Hive や Spark の毎日のジョブをトリガーし、データを処理して Hive のテーブルに書き込みます。
