---
title: Mapping data flow のパフォーマンスとチューニング ガイド
description: Azure Data Factory でのマッピング データ フローのパフォーマンスに影響する主な要因について説明します。
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.custom: seo-lt-2019
ms.date: 08/12/2020
ms.openlocfilehash: cf91dd0b7f16bf0dcd3d84da1b942b2353ec5bd0
ms.sourcegitcommit: 4913da04fd0f3cf7710ec08d0c1867b62c2effe7
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 08/14/2020
ms.locfileid: "88212034"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>Mapping Data Flow のパフォーマンスとチューニング ガイド

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Azure Data Factory のマッピング データ フローには、大規模なデータ変換を設計および実行するためのコード不要のインターフェイスが用意されています。 マッピング データ フローに慣れていない場合は、[マッピング データ フローの概要](concepts-data-flow-overview.md)に関するページを参照してください。 この記事では、パフォーマンスのベンチマークを満たすようにデータ フローを調整および最適化するさまざまな方法について説明します。

こちらのビデオをご覧ください。データ フローを使用してデータを変換するサンプルのタイミングをいくつか紹介しています。

> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE4rNxM]

## <a name="testing-data-flow-logic"></a>データ フローのロジックをテストする

ADF UX からデータ フローを設計およびテストするときは、デバッグ モードを使用すればライブ Spark クラスターに対して対話形式でテストできます。 これにより、クラスターがウォームアップされるのを待たずにデータをプレビューし、データ フローを実行することができます。 詳細については、[デバッグ モード](concepts-data-flow-debug-mode.md)に関するページを参照してください。

## <a name="monitoring-data-flow-performance"></a>データ フローのパフォーマンスを監視する

デバッグ モードを使用して変換ロジックを確認したら、パイプラインでアクティビティとしてデータ フローをエンドツーエンドで実行します。 データ フローは、パイプラインで[データ フローの実行アクティビティ](control-flow-execute-data-flow-activity.md)を使用して運用可能にすることができます。 データ フロー アクティビティには、他の Azure Data Factory アクティビティと比較して独自の監視エクスペリエンスが用意されており、変換ロジックの詳細な実行プランとパフォーマンス プロファイルを表示できます。 データ フローの詳細な監視情報を表示するには、パイプラインのアクティビティの実行出力で眼鏡のアイコンをクリックします。 詳細については、[マッピング データ フローの監視](concepts-data-flow-monitoring.md)に関するページを参照してください。

![データ フローの監視](media/data-flow/monitoring-details.png "データ フローの監視 2")

データ フローのパフォーマンスを監視する際には、次の 4 つのボトルネックが考えられます。

* クラスターの起動時間
* ソースからの読み取り
* 変換時間
* シンクへの書き込み 

![データ フローの監視](media/data-flow/monitoring-performance.png "データ フローの監視 3")

クラスターの起動時間は、Apache Spark クラスターをスピンアップするためにかかる時間です。 この値は、監視画面の右上隅にあります。 データ フローは、各ジョブが分離クラスターを使用する Just-In-Time モデルで実行されます。 通常、この起動時間は 3 - 5 分かかります。 シーケンシャル ジョブの場合は、Time to Live を有効にすることで、これを短縮できます。 詳細については、「[Azure Integration Runtime の最適化](#ir)」を参照してください。

データ フローには、可能な限り迅速な実行のためにビジネス ロジックを "ステージ" で並べ替えて実行する、Spark オプティマイザーが利用されます。 データ フローの書き込み先の各シンクについて、監視出力には、各変換ステージの期間と、シンクへのデータの書き込みにかかる時間が表示されます。 最大の時間は、データ フローのボトルネックになる可能性があります。 最も時間のかかる変換ステージにソースが含まれている場合は、読み取り時間をさらに最適化することをお勧めします。 変換に長い時間がかかっている場合は、統合ランタイムのパーティション再分割を行うか、サイズを増やす必要があります。 シンクの処理時間が長い場合は、データベースをスケールアップするか、1 つのファイルに出力していないことを確認する必要があります。

データ フローのボトルネックを特定したら、以下の最適化戦略を使用してパフォーマンスを向上させます。

## <a name="optimize-tab"></a>[最適化] タブ

**[最適化]** タブには、Spark クラスターのパーティション分割を構成するための設定が含まれています。 データ フローのすべての変換に存在するこのタブでは、変換が完了した**後**にデータのパーティション再分割を行うかどうかを指定します。 パーティション分割を調整すると、全体的なデータ フローのパフォーマンスに好影響を与えることも、悪影響も与えることもある、各計算ノードへのデータの分散とデータの局所性の最適化を制御できます。

![最適化](media/data-flow/optimize.png "最適化")

既定では、変換の現在の出力パーティション分割を維持するよう Azure Data Factory に指示する *[Use current partitioning]\(現在のパーティション分割を使用する\)* が選択されています。 データのパーティション再分割は時間がかかるため、ほとんどのシナリオでは、 *[Use current partitioning]\(現在のパーティション分割を使用する\)* をお勧めします。 データのパーティションを再分割する必要があるシナリオとしては、集計や結合によってデータが大幅にスキューされた場合や、SQL DB でソースのパーティション分割を使用する場合があります。

いずれかの変換でパーティション分割を変更する場合は、 **[最適化]** タブを選択し、 **[Set Partitioning]\(パーティションの設定\)** を選択します。 パーティション分割用の一連のオプションが表示されます。 パーティション分割の最適な方法は、データ ボリューム、候補キー、null 値、およびカーディナリティに応じて異なります。 

> [!IMPORTANT]
> すべての分散データを 1 つのパーティションに結合するのが単一パーティションです。 これは非常に低速な操作であると同時に、すべてのダウンストリームの変換と書き込みに大きな影響を及ぼします。 Azure Data Factory においては、明示的な業務上の理由がない限り、このオプションを使用しないことを強くお勧めします。

すべての変換で次のパーティション分割オプションを使用できます。

### <a name="round-robin"></a>ラウンド ロビン 

データを複数のパーティションに均等に分散するのがラウンド ロビンです。 堅固でスマートなパーティション分割戦略を実装するための適切な候補がないときは、ラウンド ロビンを使用します。 物理パーティションの数を設定できます。

### <a name="hash"></a>ハッシュ インデックス

Azure Data Factory は、同様の値を持つ行が同じパーティション内に分類されるように、列のハッシュを生成して統一されたパーティションを生成します。 [ハッシュ] オプションを使用するときは、起こり得るパーティションのスキューについてテストします。 物理パーティションの数を設定できます。

### <a name="dynamic-range"></a>動的範囲

動的範囲では、指定した列または式に基づく Spark の動的範囲が使用されます。 物理パーティションの数を設定できます。 

### <a name="fixed-range"></a>固定範囲

パーティション分割されたデータ列内の値に対する固定の範囲を提供する式を作成します。 パーティションのスキューを避けるため、このオプションを使用する際は、自分のデータについて十分に理解する必要があります。 式に入力する値は、パーティション関数の一部として使用されます。 物理パーティションの数を設定できます。

### <a name="key"></a>Key

データのカーディナリティを十分に理解している場合は、キー パーティション分割が適切な戦略になるでしょう。 キー パーティション分割では、列内の一意の値ごとにパーティションが作成されます。 パーティションの数は、データ内の一意の値に基づくため、設定することはできません。

> [!TIP]
> パーティション構成を手動で設定すると、データが再シャッフルされ、Spark オプティマイザーの利点が相殺される可能性があります。 必要な場合を除き、パーティション分割を手動で設定しないことをお勧めします。

## <a name="optimizing-the-azure-integration-runtime"></a><a name="ir"></a>Azure Integration Runtime の最適化

データ フローは、実行時にスピンアップされる Spark クラスター上で実行されます。 使用されるクラスターの構成は、アクティビティの統合ランタイム (IR) 内に定義されます。 統合ランタイムを定義する際は、クラスターの種類、クラスターのサイズ、Time to Live という 3 つのパフォーマンスに関する考慮事項があります。

Integration Runtime の作成方法の詳細については、「[Azure Data Factory の統合ランタイム](concepts-integration-runtime.md)」を参照してください。

### <a name="cluster-type"></a>クラスターの種類

選択できる Spark クラスターのスピンアップの種類には、汎用、メモリ最適化、コンピューティング最適化の 3 つのオプションがあります。

**汎用**クラスターは既定で選択されており、ほとんどのデータ フロー ワークロードに適しています。 パフォーマンスとコストのバランスが最適になる傾向があります。

データ フローに多数の結合と参照が含まれている場合は、**メモリ最適化**クラスターを使用することをお勧めします。 メモリ最適化クラスターでは、より多くのデータをメモリに格納できるため、メモリ不足のエラーを最小限に抑えることができます。 メモリ最適化は、コアあたりの価格ポイントが最も高いだけでなく、より満足のいくパイプラインになる傾向もあります。 データ フローの実行時にメモリ不足エラーが発生する場合は、メモリ最適化 Azure IR 構成に切り替えます。 

**コンピューティング最適化**は ETL ワークフローには適しておらず、Azure Data Factory チームでは、ほとんどの運用環境のワークロード用としてお勧めしません。 データをフィルター処理したり、派生列を追加したりするなど、メモリを多用しない簡単なデータ変換の場合は、コアあたりの価格が低めのコンピューティング最適化クラスターを使用できます。

### <a name="cluster-size"></a>クラスター サイズ

データ フローでは、データ処理を Spark クラスター内の異なる複数のノードに分散して、操作を並列で実行します。 コア数が多い Spark クラスターでは、コンピューティング環境のノード数が増加します。 ノードが増えると、データ フローの処理能力が向上します。 多くの場合、クラスターのサイズを増やすことは、処理時間を短縮するための簡単な方法です。

既定のクラスター サイズは、4 つのドライバー ノードと 4 つのワーカー ノードです。  より多くのデータを処理する場合は、より大きなクラスターを使用することをお勧めします。 可能なサイズ変更オプションは次のとおりです。

| ワーカー コア | ドライバー コア | コア総数 | Notes |
| ------------ | ------------ | ----------- | ----- |
| 4 | 4 | 8 | コンピューティング最適化には使用できません |
| 8 | 8 | 16 | |
| 16 | 16 | 32 | |
| 32 | 16 | 48 | |
| 64 | 16 | 80 | |
| 128 | 16 | 144 | |
| 256 | 16 | 272 | |

データ フローは仮想コア時間で課金されます。つまり、クラスターのサイズと実行時間の両方が考慮されます。 スケールアップすると、1 分あたりのクラスター コストが増加しますが、全体的な時間は減少します。

> [!TIP]
> クラスターのサイズがデータ フローのパフォーマンスに与える影響には上限があります。 データのサイズによっては、クラスターのサイズを大きくしてもパフォーマンスが向上しなくなるポイントがあります。 たとえば、データのパーティション数よりも多くのノードがある場合、ノードを追加しても役に立ちません。 ベスト プラクティスとして、小規模に開始し、パフォーマンスのニーズに合わせてスケールアップすることをお勧めします。 

### <a name="time-to-live"></a>Time to Live

既定では、すべてのデータ フロー アクティビティで、IR 構成に基づいて新しいクラスターがスピンアップされます。 クラスターの起動にかかる時間は数分で、それが完了するまではデータ処理を開始できません。 パイプラインに複数の**シーケンシャル** データ フローが含まれている場合は、Time to Live (TTL) 値を有効にすることができます。 Time to Live 値を指定すると、クラスターは実行が完了してから一定の期間、有効な状態に維持されます。 TTL 時間内に IR を使用する新しいジョブを開始すると、既存のクラスターが再利用され、開始時間は数分ではなく数秒になります。 2 番目のジョブが完了すると、クラスターは TTL 時間の間、再び有効な状態で維持されます。

1 つのクラスターで一度に実行できるジョブは 1 つだけです。 使用可能なクラスターがあり、2 つのデータ フローが開始されている場合は、その 1 つだけにライブ クラスターが使用されます。 2 番目のジョブで、それ専用の分離クラスターがスピンアップされます。

データ フローの大部分が並列で実行される場合は、TTL を有効にしないことをお勧めします。 

> [!NOTE]
> 自動解決統合ランタイムを使用する場合、Time to Live は使用できません

## <a name="optimizing-sources"></a>ソースの最適化

Azure SQL Database を除くすべてのソースについては、 **[Use current partitioning]\(現在のパーティションを使用する\)** を選択された値としてそのまま使用することをお勧めします。 他のすべてのソース システムから読み取る場合、データ フローでは、データのサイズに基づいて自動的にデータが均等にパーティション分割されます。 データ 128 MB ごとに新しいパーティションが作成されます。 データのサイズが増加するにつれて、パーティションの数が増加します。

カスタム パーティション分割は、Spark にデータが読み取られた "*後*" に発生し、データ フローのパフォーマンスに悪影響を与えます。 読み取り時にデータが均等にパーティション分割されるため、この方法はお勧めしません。 

> [!NOTE]
> 読み取り速度は、ソース システムのスループットによって制限される場合があります。

### <a name="azure-sql-database-sources"></a>Azure SQL Database のソース

Azure SQL Database には、"ソース" パーティション分割と呼ばれる独自のパーティション分割オプションがあります。 ソースのパーティション分割を有効にした場合、ソース システムで並列接続を有効にすることで、Azure SQL DB からの読み取り時間を短縮できます。 パーティションの数とデータをパーティション分割する方法を指定します。 カーディナリティが高いパーティション列を使用します。 また、ソース テーブルのパーティション構成に一致するクエリを入力することもできます。

> [!TIP]
> ソースのパーティション分割では、SQL Server の I/O がボトルネックになります。 追加するパーティションが多すぎると、ソース データベースが飽和状態になる可能性があります。 通常、このオプションを使用する場合、4 つまたは 5 つのパーティションが理想的です。

![ソースのパーティション分割](media/data-flow/sourcepart3.png "ソースのパーティション分割")

#### <a name="isolation-level"></a>分離レベル

Azure SQL ソース システムでの読み取りの分離レベルは、パフォーマンスに影響します。 [コミットされていないものを読み取り] を選択すると、パフォーマンスが最速になり、データベース ロックが防止されます。 SQL 分離レベルの詳細については、「[分離レベルについて](https://docs.microsoft.com/sql/connect/jdbc/understanding-isolation-levels?view=sql-server-ver15)」を参照してください。

#### <a name="read-using-query"></a>クエリを使用した読み取り

テーブルまたは SQL クエリを使用して Azure SQL Database から読み取ることができます。 SQL クエリを実行する場合は、変換を開始する前にクエリが完了する必要があります。 SQL クエリは、より高速に実行される可能性がある操作をプッシュ ダウンし、SELECT、WHERE、JOIN ステートメントなどの、SQL Server から読み取るデータの量を減らすのに役立ちます。 操作をプッシュ ダウンすると、データがデータ フローに取り込まれる前に、変換の系列とパフォーマンスを追跡できなくなります。

### <a name="azure-synapse-analytics-sources"></a>Azure Synapse Analytics のソース

Azure Synapse Analytics を使用するとき、ソース オプションに **[Enable staging]\(ステージングの有効化\)** という設定があります。 これにより、ADF で [PolyBase](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide?view=sql-server-ver15) を使用して Synapse から読み取ることができます。そうすることで、読み取りのパフォーマンスが大幅に向上します。 PolyBase を有効にするには、データ フロー アクティビティの設定で Azure Blob Storage または Azure Data Lake Storage gen2 ステージングの場所を指定する必要があります。

![ステージングの有効化](media/data-flow/enable-staging.png "ステージングの有効化")

### <a name="file-based-sources"></a>ファイルベースのソース

さまざまな種類のファイルがデータ フローでサポートされていますが、Azure Data Factory では、読み取りと書き込みを最適に行うために、Spark ネイティブの Parquet 形式を使用することをお勧めします。

一連のファイルで同じデータ フローを実行している場合は、ワイルドカード パスを使用して、またはファイルの一覧から読み取ることで、フォルダーから読み取ることをお勧めします。 1 つのデータ フロー アクティビティの実行で、バッチ内のすべてのファイルを処理できます。 これらの設定値を設定する方法の詳細については、[Azure Blob Storage](connector-azure-blob-storage.md#source-transformation) などのコネクタのドキュメントを参照してください。

可能な場合、一連のファイルに対し、For Each アクティビティを使用してデータ フローを実行することは避けてください。 for-each の各反復処理に専用の Spark クラスターが作成されることになるのですが、これは必要でないことが多く、コストが高くなる可能性があります。 

## <a name="optimizing-sinks"></a>シンクの最適化

データ フローからシンクに書き込むとき、カスタム パーティション分割は書き込みの直前に発生します。 ソースと同様に、ほとんどの場合、 **[Use current partitioning]\(現在のパーティション分割を使用する\)** を選択されたパーティション オプションとしてそのまま使用することをお勧めします。 パーティション分割されたデータは、書き込み先がパーティションに分割されていない場合でも、パーティション分割されていないデータよりも大幅に高速に書き込まれます。 次に、さまざまなシンクの種類に関する個別の考慮事項を示します。 

### <a name="azure-sql-database-sinks"></a>Azure SQL Database のシンク

Azure SQL Database では、ほとんどの場合、既定のパーティション分割が有効です。 シンクに含まれるパーティションが多すぎると SQL データベースで処理できない可能性があります。 これが発生した場合は、SQL Database シンクによって出力されるパーティションの数を減らします。

#### <a name="disabling-indexes-using-a-sql-script"></a>SQL スクリプトを使用したインデックスの無効化

SQL データベースで読み込み前にインデックスを無効にすると、テーブルへの書き込みのパフォーマンスが大幅に向上します。 SQL シンクに書き込む前に、次のコマンドを実行します。

`ALTER INDEX ALL ON dbo.[Table Name] DISABLE`

書き込みが完了したら、次のコマンドを使用してインデックスを再構築します。

`ALTER INDEX ALL ON dbo.[Table Name] REBUILD`

これらは両方とも、マッピング データ フローの Azure SQL DB または Synapse シンク内で、Post-SQL スクリプトを使用してネイティブに実行できます。

![インデックスの無効化](media/data-flow/disable-indexes-sql.png "インデックスの無効化")

> [!WARNING]
> インデックスを無効にすると、実質的にデータ フローでデータベースが制御されますが、クエリはこの時点では成功しない可能性があります。 その結果、この競合を回避するために、多くの ETL ジョブが夜間にトリガーされます。 詳細については、[インデックス無効化の制約](https://docs.microsoft.com/sql/relational-databases/indexes/disable-indexes-and-constraints?view=sql-server-ver15)に関するページを参照してください

#### <a name="scaling-up-your-database"></a>データベースのスケールアップ

DTU の制限に達したら、ソースとシンクの Azure SQL DB と DW のサイズ変更をスケジュールしてから、パイプラインを実行して、スループットを増やし、Azure スロットルを最小化します。 パイプラインの実行が完了したら、データベースのサイズを変更して通常のラン レートに戻します。

### <a name="azure-synapse-analytics-sinks"></a>Azure Synapse Analytics のシンク

Azure Synapse Analytics に書き込むときは、 **[Enable staging]\(ステージングの有効化\)** が true に設定されていることを確認してください。 これにより、ADF で [PolyBase](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide) を使用して書き込むことができ、データを一括で効率的に読み込むことができます。 PolyBase を使用する場合は、データのステージングのために Azure Data Lake Storage gen2 または Azure Blob Storage アカウントを参照する必要があります。

PolyBase 以外でも、Azure Synapse Analytics に Azure SQL Database と同じベスト プラクティスが適用されます。

### <a name="file-based-sinks"></a>ファイルベースのシンク 

さまざまな種類のファイルがデータ フローでサポートされていますが、Azure Data Factory では、読み取りと書き込みを最適に行うために、Spark ネイティブの Parquet 形式を使用することをお勧めします。

データが均等に分散されている場合は、 **[Use current partitioning]\(現在のパーティション分割を使用する\)** が、ファイルを書き込むための最も高速なパーティション分割オプションになります。

#### <a name="file-name-options"></a>ファイル名のオプション

ファイルの作成時、それぞれにパフォーマンスへの影響がある名前付けオプションを選択できます。

![シンクのオプション](media/data-flow/file-sink-settings.png "シンク オプション")

**[既定]** オプションを選択すると、書き込みが最速になります。 各パーティションは、Spark の既定の名前を持つファイルに相当します。 これは、データのフォルダーから読み取るだけの場合に便利です。

名前付けの**パターン**を設定すると、各パーティション ファイルの名前がわかりやすい名前に変更されます。 この操作は書き込み後に行われ、既定値を選択するよりも若干遅くなります。 パーティションごとに、個々のパーティションに手動で名前を指定できます。

希望するデータ出力方法に列が対応している場合は、 **[As data in column]\(列内のデータとして\)** を選択できます。 これによりデータが再シャッフルされ、列が均等に分散されていない場合には、パフォーマンスに影響を与える可能性があります。

**[Output to single file]\(単一ファイルへの出力\)** では、すべてのデータが単一のパーティションに結合されます。 これにより、特に大規模なデータセットでは、書き込み時間が長くなります。 Azure Data Factory チームでは、明示的な業務上の理由がない限り、このオプションを選択**しない**ことを強くお勧めします。

### <a name="cosmosdb-sinks"></a>CosmosDB のシンク

CosmosDB に書き込む場合、データ フローの実行中にスループットとバッチ サイズを変更すると、パフォーマンスが向上する可能性があります。 これらの変更はデータ フロー アクティビティの実行中にのみ有効になり、終了後に元のコレクション設定に戻ります。 

**バッチ サイズ:** データの行のおおよそのサイズを計算し、行サイズ * バッチ サイズが 200 万未満であることを確認します。 その場合は、バッチ サイズを増やしてスループットを向上させます。

**スループット**: ここでより高いスループットを設定して、CosmosDB にドキュメントを高速で書き込むことができるようにします。 高いスループットの設定に基づいて、RU コストが高くなることに注意してください。

**書き込みスループット予算:** 1 分あたりの RU の合計よりも小さい値を使用してください。 多数の Spark パーティションが含まれるデータ フローがある場合、予算のスループットを設定すると、これらのパーティション間でより均等にバランスを取ることができます。


## <a name="optimizing-transformations"></a>変換の最適化

### <a name="optimizing-joins-exists-and-lookups"></a>結合、存在、参照の最適化

#### <a name="broadcasting"></a>ブロードキャスト

結合変換、参照変換、および存在変換では、一方または両方のデータ ストリームが十分に小さくワーカー ノードのメモリに収まる場合、**ブロードキャスト**を有効にすることでパフォーマンスを最適化できます。 ブロードキャストは、クラスター内のすべてのノードに小さなデータ フレームを送信するときに行います。 これにより、Spark エンジンで大きなストリーム内のデータを再シャッフルすることなく結合を実行できます。 既定では、結合の一方をブロードキャストするかどうかは、Spark エンジンによって自動的に決定されます。 受信データをよく知っていて、一方のストリームがもう一方のストリームよりも大幅に小さくなることがわかっている場合は、**固定**ブロードキャストを選択できます。 固定ブロードキャストを使用すると、選択したストリームが Spark で強制的にブロードキャストされます。 

ブロードキャストされたデータのサイズが Spark ノードに対して大きすぎると、メモリ不足エラーが発生する可能性があります。 メモリ不足エラーを回避するには、**メモリ最適化**クラスターを使用します。 データ フローの実行中にブロードキャスト タイムアウトが発生する場合は、ブロードキャストの最適化をオフにすることができます。 ただし、これにより、データ フローのパフォーマンスが低下します。

![結合変換の最適化](media/data-flow/joinoptimize.png "結合の最適化")

#### <a name="cross-joins"></a>クロス結合

結合条件でリテラル値を使用する場合、または結合の両側に複数の一致がある場合、結合は Spark でクロス結合として実行されます。 クロス結合は、結合された値を除外する完全なデカルト積です。 これは、他の結合の種類よりも大幅に遅くなります。 パフォーマンスへの影響を回避するために、結合条件の両側に必ず列参照があるようにします。

#### <a name="sorting-before-joins"></a>結合前の並べ替え

SSIS などのツールでのマージ結合とは異なり、結合変換は強制的なマージ結合操作ではありません。 結合キーを使用する場合、変換前に並べ替えを行う必要はありません。 Azure Data Factory チームでは、マッピング データ フローで並べ替え変換を使用することはお勧めしません。

### <a name="repartitioning-skewed-data"></a>非対称のデータのパーティション再分割

結合や集計などの特定の変換によってデータ パーティションが再シャッフルされるため、非対称のデータが生じることがあります。 非対称のデータは、パーティション間でデータが均等に分散されていないことを意味します。 データが大幅に非対称であると、ダウンストリーム変換とシンク書き込みの速度が低下する可能性があります。 データ フロー実行の任意の時点でデータの歪度を確認するには、監視画面で変換をクリックします。

![歪度と尖度](media/data-flow/skewness-kurtosis.png "歪度と尖度")

監視画面には、各パーティションにデータがどのように分散されているかが、歪度と尖度という 2 つのメトリックと共に示されます。 **歪度**は、データがどの程度非対称であるかを示す尺度であり、正、0、負、または未定義の値を持つことができます。 負の歪度は、左端が右側より長いことを意味します。 **尖度**は、データが大幅に非対称であるか、または軽度に非対称であるかを示す尺度です。 高い尖度値は望ましくありません。 理想的な歪度の範囲は -3 から 3 の範囲で、尖度の範囲は 10 未満です。 これらの数値を解釈する簡単な方法として、パーティション チャートを見て、1 つの棒が残りよりも大幅に大きいかどうかを確認します。

変換後にデータが均等に分割されていない場合は、[[最適化] タブ](#optimize-tab)を使用してパーティションを再分割できます。 データの再シャッフルは時間がかかり、データ フローのパフォーマンス向上につながらない場合があります。

> [!TIP]
> データのパーティションを再分割するが、データを再シャッフルするダウンストリーム変換がある場合は、結合キーとして使用される列に対してハッシュ パーティション分割を使用します。

## <a name="using-data-flows-in-pipelines"></a>パイプラインでのデータ フローの使用 

複数のデータ フローを持つ複雑なパイプラインを構築する場合、論理フローがタイミングとコストに大きな影響を与える可能性があります。 このセクションでは、さまざまなアーキテクチャ戦略の影響について説明します。

### <a name="executing-data-flows-in-parallel"></a>データ フローの並列実行

複数のデータ フローを並列に実行すると、アクティビティごとに個別の Spark クラスターが ADF によってスピンアップされます。 これにより、各ジョブを分離して並列に実行できますが、複数のクラスターが同時に実行されることになります。

データ フローが並列実行されると、複数の未使用のウォーム プールの発生につながるため、Azure IR の time to live プロパティを有効にしないことをお勧めします。

> [!TIP]
> 各アクティビティで同じデータ フローを複数回実行するのではなく、データ レイクにデータをステージして、ワイルドカード パスを使用してデータを 1 つのデータ フローで処理します。

### <a name="execute-data-flows-sequentially"></a>データ フローの順次実行

データ フロー アクティビティを順番に実行する場合は、Azure IR 構成で TTL を設定することをお勧めします。 ADF によってコンピューティング リソースが再利用されるため、クラスターの起動時間が短縮されます。 各アクティビティは引き続き分離され、実行のたびに新しい Spark コンテキストを受け取ります。

ジョブを順番に実行すると、エンドツーエンドの実行に最長の時間がかかる可能性がありますが、論理操作が明確に分離されます。

### <a name="overloading-a-single-data-flow"></a>単一データ フローのオーバーロード

すべてのロジックを 1 つのデータ フロー内に配置すると、ADF によって単一の Spark インスタンスでジョブ全体が実行されます。 これはコストを削減する方法のように思えるかもしれませんが、さまざまな論理フローを組み合わせるため、監視やデバッグが困難になる可能性があります。 1 つのコンポーネントが失敗すると、ジョブの他のすべての部分も失敗します。 Azure Data Factory チームでは、ビジネス ロジックの独立したフローによってデータ フローを整理することをお勧めしています。 データ フローが大きくなりすぎた場合、コンポーネントを分割すると、監視とデバッグが容易になります。 データ フロー内の変換の数にはハード制限はありませんが、多すぎるとジョブが複雑になります。

## <a name="next-steps"></a>次のステップ

パフォーマンスに関する Data Flow のその他の記事を参照してください。

- [Data Flow のアクティビティ](control-flow-execute-data-flow-activity.md)
- [データ フローのパフォーマンスの監視](concepts-data-flow-monitoring.md)
